{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "from sklearn.decomposition import PCA\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics \n",
    "from time import gmtime, strftime\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"NASA_turbo_fan\",\n",
    "#     name= \"with 50 data points_{}\".format(date_time),\n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.0001,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"epochs\": 100,\n",
    "#     \"loss\": nn.BCELoss(),\n",
    "#     \"batch_size\": 64,\n",
    "#     \"decay\":1e-5,\n",
    "#     'dropout': 0.5\n",
    "#     }\n",
    "# )\n",
    "configuration={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"epochs\": 100,\n",
    "    \"loss\": nn.BCELoss(),\n",
    "    \"batch_size\": 64,\n",
    "    \"decay\":1e-5,\n",
    "    'dropout': 0.5\n",
    "}\n",
    "# configuration  = wandb.config\n",
    "\n",
    "def data_loading_AZURE(data_path, label_path, batch_size, train_ratio=0.8, val_ratio=0.5):\n",
    "    data = torch.load(data_path)\n",
    "    labels = torch.load(label_path)\n",
    "    data = nn.functional.normalize(data, dim=1)\n",
    "    data = data[:700, :, :]\n",
    "    labels = labels[:700]\n",
    "    print((labels==1).sum())\n",
    "    # reshaping the dataset so  the channels will be the second dimension.\n",
    "    data = data.permute(0, 2, 1)\n",
    "    print(data.size())\n",
    "    n_samples, n_channels, n_features = data.shape\n",
    "    X_reshaped = data.reshape(n_samples, -1) \n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(sampling_strategy='minority')\n",
    "    data_resampled, labels_resampled = smote.fit_resample(X_reshaped, labels)\n",
    "    print((labels_resampled==1).sum())\n",
    "    # Reshape X_resampled back to 3D\n",
    "    data_resampled = data_resampled.reshape(-1, n_channels, n_features)\n",
    "    print(data_resampled.shape)\n",
    "    data_resampled = torch.tensor(data_resampled)\n",
    "    labels_resampled = torch.tensor(labels_resampled)\n",
    "    dataset = TensorDataset(data_resampled, labels_resampled)\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    val_size = int(val_ratio * test_size)\n",
    "    test_size = test_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "    return DataLoader(train_dataset, batch_size=batch_size, shuffle=True), DataLoader(val_dataset, batch_size=batch_size, shuffle=True), DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def data_loading_NASA(data_path, label_path, batch_size, train_ratio=0.8, val_ratio = 0.5):\n",
    "    data = torch.load(data_path)\n",
    "    labels = torch.load(label_path)\n",
    "    data = nn.functional.normalize(data, dim=1)\n",
    "    # reshaping the dataset so  the channels will be the second dimension.\n",
    "    data = data.permute(0, 2, 1)\n",
    "    print(data.size())\n",
    "    \n",
    "    def pca_reduction(data, n_components=4):\n",
    "        data_reshaped = data.reshape(-1, data.shape[1])\n",
    "\n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=n_components)\n",
    "        \n",
    "        data_reduced = pca.fit_transform(data_reshaped)\n",
    "\n",
    "        # Reshape back to (samples, n_components, time_steps)\n",
    "        data_reduced = data_reduced.reshape(data.shape[0], n_components, data.shape[2])\n",
    "\n",
    "        return data_reduced\n",
    "    print(data.dtype)\n",
    "    data = pca_reduction(data, n_components=4)\n",
    "    data =(torch.from_numpy(data)).float()\n",
    "    n_samples, n_channels, n_features = data.shape\n",
    "    X_reshaped = data.reshape(n_samples, -1) \n",
    "    \n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(sampling_strategy='minority')\n",
    "    data_resampled, labels_resampled = smote.fit_resample(X_reshaped, labels)\n",
    "    print((labels_resampled==1).sum())\n",
    "    # Reshape X_resampled back to 3D\n",
    "    data_resampled = data_resampled.reshape(-1, n_channels, n_features)\n",
    "    print(data_resampled.shape)\n",
    "    data_resampled = torch.tensor(data_resampled)\n",
    "    labels_resampled = torch.tensor(labels_resampled)\n",
    "    dataset = TensorDataset(data_resampled, labels_resampled)\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    val_size = int(val_ratio * test_size)\n",
    "    test_size = test_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "    return DataLoader(train_dataset, batch_size=batch_size, shuffle=True), DataLoader(val_dataset, batch_size=batch_size, shuffle=True), DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=8, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=8, kernel_size=5)\n",
    "        self.bn2 = nn.BatchNorm1d(8)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, padding=0, stride=1)\n",
    "        # the size of the out channels x number  of nodes \n",
    "        self.fc1 = nn.Linear(328, 200)\n",
    "        self.fc2 = nn.Linear(200, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        # x = self.relu(self.conv1(x))\n",
    "        # x = self.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x - self.dropout(x)\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(logits, y):\n",
    "    y_hat = logits.argmax(axis=1) # Finds the column with the highest value for each row of `logits`.\n",
    "    return (y_hat == y).float().sum() # Computes the number of times that `y_hat` and `y` match.\n",
    "\n",
    "def evaluate_metric(model, data_iter, metric):\n",
    "    \"\"\"Compute the average `metric` of the model on a dataset.\"\"\"\n",
    "    c = torch.tensor(0.).to(device)\n",
    "    n = torch.tensor(0.).to(device)\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(device), y.to(device) # Moves data to `device`\n",
    "        logits = model(X)\n",
    "        c += metric(logits, y)\n",
    "        n += len(y)\n",
    "    return c*100 / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([848, 24, 50])\n",
      "torch.float32\n",
      "685\n",
      "(1370, 4, 50)\n",
      "tensor(64)\n",
      "torch.Size([700, 4, 50])\n",
      "636\n",
      "(1272, 4, 50)\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loaders,test_loader, config, epochs):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['decay'])\n",
    "    losses = [] # Stores the loss for each training batch\n",
    "    train_accs = [] # Stores the training accuracy after each epoch\n",
    "    test_accs = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "        total, epoch_loss = 0, 0.0\n",
    "        model.train() # This is necessary because batch normalization behaves differently between training and evaluation\n",
    "        \n",
    "        for X, y in train_loaders:\n",
    "            X, y = X.to(device), y.to(device) # Moves data to `device`\n",
    "            logits = model(X) # Computes the logits for the batch of images `X`\n",
    "            l = loss(logits, y) # Computes the loss given the `logits` and the class vector `y`\n",
    "            optimizer.zero_grad() # Zeroes the gradients stored in the model parameters\n",
    "            l.backward() # Computes the gradient of the loss `l` with respect to the model parameters\n",
    "\n",
    "            optimizer.step() # Updates the model parameters based on the gradients stored inside them\n",
    "            epoch_loss += l\n",
    "            # train_loss = float(l)\n",
    "            # losses.append(train_loss) # Stores the loss for this batch\n",
    "        model.eval() # This is necessary because batch normalization behaves differently between training and evaluation\n",
    "        train_acc = evaluate_metric(model, train_loaders, correct)\n",
    "        train_accs.append(train_acc)\n",
    "        test_acc = evaluate_metric(model, test_loader, correct)\n",
    "        test_accs.append(test_acc)\n",
    "            # wandb.log({\"train_loss\": losses,\n",
    "            #            \"train_acc\": train_accs,\n",
    "            #            \"Epoch\": epoch + 1})\n",
    "        print(f'Epoch {epoch+1}: Training accuracy: {train_accs[-1]}.') # Computes and displays training/testing dataset accuracy.\n",
    "    print(train_accs)\n",
    "    plt.plot(list(map(lambda x: x.cpu(),train_accs)), label='Training accuracy')\n",
    "    plt.plot(list(map(lambda x: x.cpu(),test_accs)), label='Testing accuracy')\n",
    "    plt.title('accuracies')\n",
    "\n",
    "def test(model, test_loaders,  configuration):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    test_accs = []\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=configuration['learning_rate'], weight_decay=configuration['decay'])\n",
    "    test_acc = []\n",
    "    l = 0.0\n",
    "    model.eval() # This is necessary because batch normalization behaves differently between training and evaluation\n",
    "    for X, y in test_loaders:    \n",
    "        X, y = X.to(device), y.to(device) # Moves data to `device`\n",
    "        logits = model(X)\n",
    "        l = loss(logits, y).item()\n",
    "        test_acc = evaluate_metric(model, test_loaders, correct)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        # wandb.log({\"test_acc\": test_acc})\n",
    "        l /= len(test_loaders)\n",
    "        end_time = time.perf_counter()\n",
    "        # print('Testing accuracy: {test_accs[-1]}.')\n",
    "        return l, test_acc\n",
    "\n",
    "NASA = data_loading_NASA(data_path='NASA_data_50.pt', label_path= 'NASA_label_50.pt', batch_size= configuration['batch_size'])\n",
    "AZURE = data_loading_AZURE(data_path='AZURE_data_50.pt', label_path='AZURE_label_50.pt', batch_size= configuration['batch_size'])\n",
    "train_loaders = [NASA[0], AZURE[0]]\n",
    "val_loaders = [NASA[1], AZURE[1]]\n",
    "test_loaders = [NASA[2], AZURE[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "Epoch 1: Training accuracy: 49.81752014160156.\n",
      "\n",
      "Epoch 2/100\n",
      "Epoch 2: Training accuracy: 56.38685989379883.\n",
      "\n",
      "Epoch 3/100\n",
      "Epoch 3: Training accuracy: 56.29561996459961.\n",
      "\n",
      "Epoch 4/100\n",
      "Epoch 4: Training accuracy: 56.02189636230469.\n",
      "\n",
      "Epoch 5/100\n",
      "Epoch 5: Training accuracy: 54.927005767822266.\n",
      "\n",
      "Epoch 6/100\n",
      "Epoch 6: Training accuracy: 55.47445297241211.\n",
      "\n",
      "Epoch 7/100\n",
      "Epoch 7: Training accuracy: 59.30656814575195.\n",
      "\n",
      "Epoch 8/100\n",
      "Epoch 8: Training accuracy: 61.4963493347168.\n",
      "\n",
      "Epoch 9/100\n",
      "Epoch 9: Training accuracy: 63.868614196777344.\n",
      "\n",
      "Epoch 10/100\n",
      "Epoch 10: Training accuracy: 63.68613052368164.\n",
      "\n",
      "Epoch 11/100\n",
      "Epoch 11: Training accuracy: 65.51094818115234.\n",
      "\n",
      "Epoch 12/100\n",
      "Epoch 12: Training accuracy: 66.1496353149414.\n",
      "\n",
      "Epoch 13/100\n",
      "Epoch 13: Training accuracy: 66.24087524414062.\n",
      "\n",
      "Epoch 14/100\n",
      "Epoch 14: Training accuracy: 67.51824951171875.\n",
      "\n",
      "Epoch 15/100\n",
      "Epoch 15: Training accuracy: 68.70437622070312.\n",
      "\n",
      "Epoch 16/100\n",
      "Epoch 16: Training accuracy: 69.06934356689453.\n",
      "\n",
      "Epoch 17/100\n",
      "Epoch 17: Training accuracy: 69.52555084228516.\n",
      "\n",
      "Epoch 18/100\n",
      "Epoch 18: Training accuracy: 69.98175048828125.\n",
      "\n",
      "Epoch 19/100\n",
      "Epoch 19: Training accuracy: 69.16058349609375.\n",
      "\n",
      "Epoch 20/100\n",
      "Epoch 20: Training accuracy: 70.34671783447266.\n",
      "\n",
      "Epoch 21/100\n",
      "Epoch 21: Training accuracy: 69.98175048828125.\n",
      "\n",
      "Epoch 22/100\n",
      "Epoch 22: Training accuracy: 69.79927062988281.\n",
      "\n",
      "Epoch 23/100\n",
      "Epoch 23: Training accuracy: 70.71167755126953.\n",
      "\n",
      "Epoch 24/100\n",
      "Epoch 24: Training accuracy: 71.25912475585938.\n",
      "\n",
      "Epoch 25/100\n",
      "Epoch 25: Training accuracy: 69.98175048828125.\n",
      "\n",
      "Epoch 26/100\n",
      "Epoch 26: Training accuracy: 69.52555084228516.\n",
      "\n",
      "Epoch 27/100\n",
      "Epoch 27: Training accuracy: 70.80291748046875.\n",
      "\n",
      "Epoch 28/100\n",
      "Epoch 28: Training accuracy: 71.71533203125.\n",
      "\n",
      "Epoch 29/100\n",
      "Epoch 29: Training accuracy: 71.25912475585938.\n",
      "\n",
      "Epoch 30/100\n",
      "Epoch 30: Training accuracy: 71.25912475585938.\n",
      "\n",
      "Epoch 31/100\n",
      "Epoch 31: Training accuracy: 71.89781188964844.\n",
      "\n",
      "Epoch 32/100\n",
      "Epoch 32: Training accuracy: 71.53284454345703.\n",
      "\n",
      "Epoch 33/100\n",
      "Epoch 33: Training accuracy: 71.80657196044922.\n",
      "\n",
      "Epoch 34/100\n",
      "Epoch 34: Training accuracy: 72.5364990234375.\n",
      "\n",
      "Epoch 35/100\n",
      "Epoch 35: Training accuracy: 71.89781188964844.\n",
      "\n",
      "Epoch 36/100\n",
      "Epoch 36: Training accuracy: 72.62773895263672.\n",
      "\n",
      "Epoch 37/100\n",
      "Epoch 37: Training accuracy: 72.71897888183594.\n",
      "\n",
      "Epoch 38/100\n",
      "Epoch 38: Training accuracy: 72.08029174804688.\n",
      "\n",
      "Epoch 39/100\n",
      "Epoch 39: Training accuracy: 72.90145874023438.\n",
      "\n",
      "Epoch 40/100\n",
      "Epoch 40: Training accuracy: 72.81021881103516.\n",
      "\n",
      "Epoch 41/100\n",
      "Epoch 41: Training accuracy: 73.08393859863281.\n",
      "\n",
      "Epoch 42/100\n",
      "Epoch 42: Training accuracy: 73.72262573242188.\n",
      "\n",
      "Epoch 43/100\n",
      "Epoch 43: Training accuracy: 73.90511322021484.\n",
      "\n",
      "Epoch 44/100\n",
      "Epoch 44: Training accuracy: 73.72262573242188.\n",
      "\n",
      "Epoch 45/100\n",
      "Epoch 45: Training accuracy: 75.09123992919922.\n",
      "\n",
      "Epoch 46/100\n",
      "Epoch 46: Training accuracy: 75.0.\n",
      "\n",
      "Epoch 47/100\n",
      "Epoch 47: Training accuracy: 74.36131286621094.\n",
      "\n",
      "Epoch 48/100\n",
      "Epoch 48: Training accuracy: 75.09123992919922.\n",
      "\n",
      "Epoch 49/100\n",
      "Epoch 49: Training accuracy: 75.09123992919922.\n",
      "\n",
      "Epoch 50/100\n",
      "Epoch 50: Training accuracy: 75.18247985839844.\n",
      "\n",
      "Epoch 51/100\n",
      "Epoch 51: Training accuracy: 76.1861343383789.\n",
      "\n",
      "Epoch 52/100\n",
      "Epoch 52: Training accuracy: 76.00364685058594.\n",
      "\n",
      "Epoch 53/100\n",
      "Epoch 53: Training accuracy: 75.91240692138672.\n",
      "\n",
      "Epoch 54/100\n",
      "Epoch 54: Training accuracy: 75.36495971679688.\n",
      "\n",
      "Epoch 55/100\n",
      "Epoch 55: Training accuracy: 76.36861419677734.\n",
      "\n",
      "Epoch 56/100\n",
      "Epoch 56: Training accuracy: 75.54744720458984.\n",
      "\n",
      "Epoch 57/100\n",
      "Epoch 57: Training accuracy: 76.36861419677734.\n",
      "\n",
      "Epoch 58/100\n",
      "Epoch 58: Training accuracy: 76.27737426757812.\n",
      "\n",
      "Epoch 59/100\n",
      "Epoch 59: Training accuracy: 76.00364685058594.\n",
      "\n",
      "Epoch 60/100\n",
      "Epoch 60: Training accuracy: 76.1861343383789.\n",
      "\n",
      "Epoch 61/100\n",
      "Epoch 61: Training accuracy: 76.91606140136719.\n",
      "\n",
      "Epoch 62/100\n",
      "Epoch 62: Training accuracy: 76.642333984375.\n",
      "\n",
      "Epoch 63/100\n",
      "Epoch 63: Training accuracy: 76.642333984375.\n",
      "\n",
      "Epoch 64/100\n",
      "Epoch 64: Training accuracy: 76.73357391357422.\n",
      "\n",
      "Epoch 65/100\n",
      "Epoch 65: Training accuracy: 77.4635009765625.\n",
      "\n",
      "Epoch 66/100\n",
      "Epoch 66: Training accuracy: 76.45985412597656.\n",
      "\n",
      "Epoch 67/100\n",
      "Epoch 67: Training accuracy: 77.18978118896484.\n",
      "\n",
      "Epoch 68/100\n",
      "Epoch 68: Training accuracy: 77.73722839355469.\n",
      "\n",
      "Epoch 69/100\n",
      "Epoch 69: Training accuracy: 77.91970825195312.\n",
      "\n",
      "Epoch 70/100\n",
      "Epoch 70: Training accuracy: 78.19342803955078.\n",
      "\n",
      "Epoch 71/100\n",
      "Epoch 71: Training accuracy: 78.19342803955078.\n",
      "\n",
      "Epoch 72/100\n",
      "Epoch 72: Training accuracy: 77.55474090576172.\n",
      "\n",
      "Epoch 73/100\n",
      "Epoch 73: Training accuracy: 79.01459503173828.\n",
      "\n",
      "Epoch 74/100\n",
      "Epoch 74: Training accuracy: 78.28466796875.\n",
      "\n",
      "Epoch 75/100\n",
      "Epoch 75: Training accuracy: 77.91970825195312.\n",
      "\n",
      "Epoch 76/100\n",
      "Epoch 76: Training accuracy: 77.8284683227539.\n",
      "\n",
      "Epoch 77/100\n",
      "Epoch 77: Training accuracy: 79.10584259033203.\n",
      "\n",
      "Epoch 78/100\n",
      "Epoch 78: Training accuracy: 79.10584259033203.\n",
      "\n",
      "Epoch 79/100\n",
      "Epoch 79: Training accuracy: 78.28466796875.\n",
      "\n",
      "Epoch 80/100\n",
      "Epoch 80: Training accuracy: 79.92700958251953.\n",
      "\n",
      "Epoch 81/100\n",
      "Epoch 81: Training accuracy: 78.92335510253906.\n",
      "\n",
      "Epoch 82/100\n",
      "Epoch 82: Training accuracy: 78.10218811035156.\n",
      "\n",
      "Epoch 83/100\n",
      "Epoch 83: Training accuracy: 79.83576965332031.\n",
      "\n",
      "Epoch 84/100\n",
      "Epoch 84: Training accuracy: 80.20072937011719.\n",
      "\n",
      "Epoch 85/100\n",
      "Epoch 85: Training accuracy: 79.92700958251953.\n",
      "\n",
      "Epoch 86/100\n",
      "Epoch 86: Training accuracy: 79.92700958251953.\n",
      "\n",
      "Epoch 87/100\n",
      "Epoch 87: Training accuracy: 79.28832244873047.\n",
      "\n",
      "Epoch 88/100\n",
      "Epoch 88: Training accuracy: 80.2919692993164.\n",
      "\n",
      "Epoch 89/100\n",
      "Epoch 89: Training accuracy: 79.65328216552734.\n",
      "\n",
      "Epoch 90/100\n",
      "Epoch 90: Training accuracy: 80.10948944091797.\n",
      "\n",
      "Epoch 91/100\n",
      "Epoch 91: Training accuracy: 80.93065643310547.\n",
      "\n",
      "Epoch 92/100\n",
      "Epoch 92: Training accuracy: 80.2919692993164.\n",
      "\n",
      "Epoch 93/100\n",
      "Epoch 93: Training accuracy: 80.10948944091797.\n",
      "\n",
      "Epoch 94/100\n",
      "Epoch 94: Training accuracy: 80.2919692993164.\n",
      "\n",
      "Epoch 95/100\n",
      "Epoch 95: Training accuracy: 81.1131362915039.\n",
      "\n",
      "Epoch 96/100\n",
      "Epoch 96: Training accuracy: 80.20072937011719.\n",
      "\n",
      "Epoch 97/100\n",
      "Epoch 97: Training accuracy: 81.56934356689453.\n",
      "\n",
      "Epoch 98/100\n",
      "Epoch 98: Training accuracy: 81.75182342529297.\n",
      "\n",
      "Epoch 99/100\n",
      "Epoch 99: Training accuracy: 81.66058349609375.\n",
      "\n",
      "Epoch 100/100\n",
      "Epoch 100: Training accuracy: 81.1131362915039.\n",
      "[tensor(49.8175, device='cuda:0'), tensor(56.3869, device='cuda:0'), tensor(56.2956, device='cuda:0'), tensor(56.0219, device='cuda:0'), tensor(54.9270, device='cuda:0'), tensor(55.4745, device='cuda:0'), tensor(59.3066, device='cuda:0'), tensor(61.4963, device='cuda:0'), tensor(63.8686, device='cuda:0'), tensor(63.6861, device='cuda:0'), tensor(65.5109, device='cuda:0'), tensor(66.1496, device='cuda:0'), tensor(66.2409, device='cuda:0'), tensor(67.5182, device='cuda:0'), tensor(68.7044, device='cuda:0'), tensor(69.0693, device='cuda:0'), tensor(69.5256, device='cuda:0'), tensor(69.9818, device='cuda:0'), tensor(69.1606, device='cuda:0'), tensor(70.3467, device='cuda:0'), tensor(69.9818, device='cuda:0'), tensor(69.7993, device='cuda:0'), tensor(70.7117, device='cuda:0'), tensor(71.2591, device='cuda:0'), tensor(69.9818, device='cuda:0'), tensor(69.5256, device='cuda:0'), tensor(70.8029, device='cuda:0'), tensor(71.7153, device='cuda:0'), tensor(71.2591, device='cuda:0'), tensor(71.2591, device='cuda:0'), tensor(71.8978, device='cuda:0'), tensor(71.5328, device='cuda:0'), tensor(71.8066, device='cuda:0'), tensor(72.5365, device='cuda:0'), tensor(71.8978, device='cuda:0'), tensor(72.6277, device='cuda:0'), tensor(72.7190, device='cuda:0'), tensor(72.0803, device='cuda:0'), tensor(72.9015, device='cuda:0'), tensor(72.8102, device='cuda:0'), tensor(73.0839, device='cuda:0'), tensor(73.7226, device='cuda:0'), tensor(73.9051, device='cuda:0'), tensor(73.7226, device='cuda:0'), tensor(75.0912, device='cuda:0'), tensor(75., device='cuda:0'), tensor(74.3613, device='cuda:0'), tensor(75.0912, device='cuda:0'), tensor(75.0912, device='cuda:0'), tensor(75.1825, device='cuda:0'), tensor(76.1861, device='cuda:0'), tensor(76.0036, device='cuda:0'), tensor(75.9124, device='cuda:0'), tensor(75.3650, device='cuda:0'), tensor(76.3686, device='cuda:0'), tensor(75.5474, device='cuda:0'), tensor(76.3686, device='cuda:0'), tensor(76.2774, device='cuda:0'), tensor(76.0036, device='cuda:0'), tensor(76.1861, device='cuda:0'), tensor(76.9161, device='cuda:0'), tensor(76.6423, device='cuda:0'), tensor(76.6423, device='cuda:0'), tensor(76.7336, device='cuda:0'), tensor(77.4635, device='cuda:0'), tensor(76.4599, device='cuda:0'), tensor(77.1898, device='cuda:0'), tensor(77.7372, device='cuda:0'), tensor(77.9197, device='cuda:0'), tensor(78.1934, device='cuda:0'), tensor(78.1934, device='cuda:0'), tensor(77.5547, device='cuda:0'), tensor(79.0146, device='cuda:0'), tensor(78.2847, device='cuda:0'), tensor(77.9197, device='cuda:0'), tensor(77.8285, device='cuda:0'), tensor(79.1058, device='cuda:0'), tensor(79.1058, device='cuda:0'), tensor(78.2847, device='cuda:0'), tensor(79.9270, device='cuda:0'), tensor(78.9234, device='cuda:0'), tensor(78.1022, device='cuda:0'), tensor(79.8358, device='cuda:0'), tensor(80.2007, device='cuda:0'), tensor(79.9270, device='cuda:0'), tensor(79.9270, device='cuda:0'), tensor(79.2883, device='cuda:0'), tensor(80.2920, device='cuda:0'), tensor(79.6533, device='cuda:0'), tensor(80.1095, device='cuda:0'), tensor(80.9307, device='cuda:0'), tensor(80.2920, device='cuda:0'), tensor(80.1095, device='cuda:0'), tensor(80.2920, device='cuda:0'), tensor(81.1131, device='cuda:0'), tensor(80.2007, device='cuda:0'), tensor(81.5693, device='cuda:0'), tensor(81.7518, device='cuda:0'), tensor(81.6606, device='cuda:0'), tensor(81.1131, device='cuda:0')]\n",
      "Epoch 1: validation loss 0.2078323761622111, accuracy 69.34306335449219\n",
      "Final test set performance:\n",
      "\tloss 0.17488559087117514\n",
      "\taccuracy 72.9926986694336\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGzCAYAAACPa3XZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACAcklEQVR4nO3dd3hU1dbA4d/MpHdID6mE3jtSRTqKepWLoqhgL1ixX7texa7XXq5i189+LUiVLl16TygB0kggvWfO98eemcwkkzIpk7be55lnTs45c2bPRDkre6+9tk7TNA0hhBBCCCfRN3cDhBBCCNG+SPAhhBBCCKeS4EMIIYQQTiXBhxBCCCGcSoIPIYQQQjiVBB9CCCGEcCoJPoQQQgjhVBJ8CCGEEMKpJPgQQgghhFNJ8CGEaBM++eQTdDodx44da+6mCCFqIcGHEEIIIZxKJ2u7CCHagvLyckpLS3F3d0en0zV3c4QQNZCeDyGE0+Xn5zf6NQ0GAx4eHhJ4CNEKSPAhRBtw/PhxbrvtNrp3746npyeBgYHMnDnTbv5DVlYW99xzD7Gxsbi7uxMZGck111xDRkaG5ZyioiKefPJJunXrhoeHB+Hh4Vx66aUkJiYCsGrVKnQ6HatWrbK59rFjx9DpdHzyySeWfXPnzsXHx4fExETOP/98fH19mT17NgBr165l5syZREdH4+7uTlRUFPfccw+FhYVV2n3gwAEuu+wygoOD8fT0pHv37jzyyCOW49XlfPzxxx+MGTMGb29vfH19ueCCC9i7d6/NOampqVx77bVERkbi7u5OeHg4F198seSPCNFEXJq7AUKIhtuyZQt//fUXs2bNIjIykmPHjvHuu+8ybtw49u3bh5eXFwB5eXmMGTOG/fv3c9111zFo0CAyMjL45ZdfOHnyJEFBQZSXlzN9+nRWrFjBrFmzuOuuu8jNzWXZsmXs2bOH+Ph4h9tXVlbGlClTGD16NC+//LKlPd999x0FBQXceuutBAYGsnnzZt58801OnjzJd999Z3n9rl27GDNmDK6urtx0003ExsaSmJjIr7/+yrPPPlvt+37++efMmTOHKVOm8MILL1BQUMC7777L6NGj2b59O7GxsQDMmDGDvXv3cscddxAbG0t6ejrLli0jKSnJco4QohFpQohWr6CgoMq+DRs2aID22WefWfY9/vjjGqD9+OOPVc43Go2apmnaxx9/rAHaq6++Wu05K1eu1ABt5cqVNsePHj2qAdrChQst++bMmaMB2kMPPVSndi9YsEDT6XTa8ePHLfvGjh2r+fr62uyzbo+madrChQs1QDt69KimaZqWm5urBQQEaDfeeKPNa1JTUzV/f3/L/rNnz2qA9tJLL1VpixCiaciwixBtgKenp2W7tLSUzMxMunTpQkBAAH///bfl2A8//ED//v255JJLqlzDnCvxww8/EBQUxB133FHtOfVx66231tju/Px8MjIyGDlyJJqmsX37dgBOnz7NmjVruO6664iOjq5ze5YtW0ZWVhZXXHEFGRkZlofBYGD48OGsXLnS0gY3NzdWrVrF2bNn6/35hBB1J8GHEG1AYWEhjz/+OFFRUbi7uxMUFERwcDBZWVlkZ2dbzktMTKRPnz41XisxMZHu3bvj4tJ4o7IuLi5ERkZW2Z+UlMTcuXPp2LEjPj4+BAcHc+655wJY2n3kyBGAWttd2eHDhwEYP348wcHBNo+lS5eSnp4OgLu7Oy+88AJ//PEHoaGhjB07lhdffJHU1NR6f14hRM0k50OINuCOO+5g4cKF3H333YwYMQJ/f390Oh2zZs3CaDQ2+vtV1+NQXl5ud7+7uzt6vb7KuZMmTeLMmTM8+OCD9OjRA29vb06dOsXcuXMb3G7z6z///HPCwsKqHLcOru6++24uvPBCfv75Z5YsWcJjjz3GggUL+PPPPxk4cGCD2iGEqEqCDyHagO+//545c+bwyiuvWPYVFRWRlZVlc158fDx79uyp8Vrx8fFs2rSJ0tJSXF1d7Z7ToUMHgCrXP378eJ3bvHv3bg4dOsSnn37KNddcY9m/bNkym/M6d+4MUGu7KzMnxoaEhDBx4sQ6nX/vvfdy7733cvjwYQYMGMArr7zCF1984dD7CiFqJ8MuQrQBBoMBrVK9wDfffLNKT8SMGTPYuXMnP/30U5VrmF8/Y8YMMjIyeOutt6o9JyYmBoPBwJo1a2yOv/POOw612fqa5u3//Oc/NucFBwczduxYPv74Y5KSkuy2x54pU6bg5+fHc889R2lpaZXjp0+fBqCgoICioiKbY/Hx8fj6+lJcXFznzyOEqDvp+RCiDZg+fTqff/45/v7+9OrViw0bNrB8+XICAwNtzrv//vv5/vvvmTlzJtdddx2DBw/mzJkz/PLLL7z33nv079+fa665hs8++4z58+ezefNmxowZQ35+PsuXL+e2227j4osvxt/fn5kzZ/Lmm2+i0+mIj4/nt99+s+RR1EWPHj2Ij4/nvvvu49SpU/j5+fHDDz/YTfp84403GD16NIMGDeKmm24iLi6OY8eO8fvvv7Njxw671/fz8+Pdd9/l6quvZtCgQcyaNYvg4GCSkpL4/fffGTVqFG+99RaHDh1iwoQJXHbZZfTq1QsXFxd++ukn0tLSmDVrlkO/ByFEHTXjTBshRCM5e/asdu2112pBQUGaj4+PNmXKFO3AgQNaTEyMNmfOHJtzMzMztdtvv13r1KmT5ubmpkVGRmpz5szRMjIyLOcUFBRojzzyiBYXF6e5urpqYWFh2j//+U8tMTHRcs7p06e1GTNmaF5eXlqHDh20m2++WduzZ4/dqbbe3t52271v3z5t4sSJmo+PjxYUFKTdeOON2s6dO6tcQ9M0bc+ePdoll1yiBQQEaB4eHlr37t21xx57zHK88lRbs5UrV2pTpkzR/P39NQ8PDy0+Pl6bO3eutnXrVk3TNC0jI0ObN2+e1qNHD83b21vz9/fXhg8frn377bcO/AaEEI6QtV2EEEII4VSS8yGEEEIIp5LgQwghhBBOJcGHEEIIIZxKgg8hhBBCOJUEH0IIIYRwKgk+hBBCCOFULa7ImNFoJDk5GV9f3watoCmEEEII59E0jdzcXCIiIqqs5VRZiws+kpOTiYqKau5mCCGEEKIeTpw4YXcVa2stLvjw9fUFVOP9/PyauTVCCCGEqIucnByioqIs9/GatLjgwzzU4ufnJ8GHEEII0crUJWVCEk6FEEII4VQSfAghhBDCqST4EEIIIYRTSfAhhBBCCKeS4EMIIYQQTiXBhxBCCCGcSoIPIYQQQjiVBB9CCCGEcCoJPoQQQgjhVBJ8CCGEEMKpJPgQQgghhFNJ8CGEEEIIp2pxC8sJIYQQwnEJ6Xks2p1CgJcr/SMD6BHui7uLobmbZZcEH0IIIUQrVW7UWLE/jc82HGddQobNMTeDnp4RfozpEsTt47vg4dpyAhEJPoQQQohWaMneVJ7+dR+nsgoB0OvgvO4hlGsaO09kcbaglJ0nsth5IovUnCJe+me/Oi137wwSfAghhBCtTFFpOff83w4KSsrp4OXK5UOjueqcaCI7eAGgaRonzhSy5vBpHv/fHr7fdpL+kf5cPSK2eRtuIsGHEEII0cqsOXSagpJyOgV4suLec6sMqeh0OqIDvbgqMIaCkjKeW3SAp37dR68IPwbHdGymVleQ2S5CCCFEK7NkbxoAk3uH1prLceOYzlzQL5wyo8YtX/xNek6RM5pYIwk+hBBCiFakrNzIigOm4KNXWK3n63Q6XpzRj26hPpzOLea2L/+mpMzY1M2skQQfQgghRAuiaRqP/byHB77fSblRq3J887EzZBWU0sHLlaGxHep0TW93F96/egi+Hi5sPX6Wf/++r7Gb7RAJPoQQQogWZOm+ND7feJxvt55k6d7UqsdNQy4Te4biYqj7bTwuyJvXLx8AwLJ9aZzNL2mU9taHBB9CCCFEI8jIK+Yfb6/n37/Vv1eh3Kjx8pKDlp/fWZWIplX0fmiaZglIpvSufcilsgk9Q3n1sv78esdoOni71budDSXBhxBCCNEI3lxxmB0nsvjvuqMs2p1Sr2v8vP0Uh9Pz8PNwwdPVwO5T2aw9XFE8bPepbJKzi/ByMzC6a1C93uPSQZEE+bjX67WNRYIPIYQQooFOnCngq81Jlp8f/XkPp3OLHbpGSZmR15YfAuDWcV24Ylg0AG+vTLCcs8TU6zGue3CLqljqKAk+hBBCiAZ6bfkhSss1RnQOpGe4H2fyS3jkp902Qya1+XpzEifPFhLi687ckbHcODYOV4OOTUfPsO34GaBiim19hlxaEgk+hBBCiAY4lJbLT9tPAfDQtB68MrM/rgYdS/el8fOOU3W6RkFJGW/+qXo47pjQFU83A+H+nlwysBMA76xMJPF0HgnpebgadJzXI6RpPoyTSPAhhBBCNMArSw+iaTC1dxj9owLoFeHHXRO6AvD4//aSkl1Y6zUWrj9GRl4x0R29uHxIlGX/LefGo9PBigPpvLHiMAAj4oPw83Btmg/jJBJ8CCGEEJUUlJSRkVd7zsaOE1ks2ZuGXgf3Telm2X/LufH0j/Qnt6iMB3+oefglu6CU91cnAjB/UjfcXCpuzZ2DfTi/TzgA/9uRDMCU3qH1+kwtiUPBR3l5OY899hhxcXF4enoSHx/PM888U2Ua0OOPP054eDienp5MnDiRw4cPN3rDhRBCiMpSs4s408D6FUajxqwPNjL6hT/Zcyq7xnNfWnIAUDNIuoT4Wva7GPS8cll/3Fz0rDl0mmn/WcvXm5MoKCmznHM2v4T3Vidy/htrySkqo0eYLxf1j6jyHreOi7ds63QwqVc7Cz5eeOEF3n33Xd566y3279/PCy+8wIsvvsibb75pOefFF1/kjTfe4L333mPTpk14e3szZcoUioqav5a8EEKItuuHbScZ++JKRj3/J/9de4Sy8vqVEF+XkMGuk9kUlRqZ/+0OisvK7Z63PiGD9QmZuBn03D2xa5XjXUJ8ee6Svni46jmQmsvDP+7mnOdW8Mxv+7jvu50MX7CC5/84wKmsQjp4ufLsJX3Q66sued+nkz/ndgsGYGBUACG+HvX6XC2JTnMgFXf69OmEhoby0UcfWfbNmDEDT09PvvjiCzRNIyIignvvvZf77rsPgOzsbEJDQ/nkk0+YNWtWre+Rk5ODv78/2dnZ+Pn51eMjCSGEaE+MRo2Xlx7knVWJNvv7dvJnwaV96dPJ36HrXbtwMysPnrb8fOu4eB6c2sPmnNO5xcx87y+OZRYwd2QsT17Uu9rrZReU8t22E3y24ThJZwpsjvXp5MecEbFc2D+ixqmzCem5PPHLXm4b14VRXepX36OpOXL/dnHkwiNHjuSDDz7g0KFDdOvWjZ07d7Ju3TpeffVVAI4ePUpqaioTJ060vMbf35/hw4ezYcMGu8FHcXExxcUV42o5OTmONEkIIUQbsPnoGbqH+uLv5VgiZWFJOff83w4Wm+pfzDsvnsgOXixYtJ/dp7K5+O31zBkRS59OtjfDbqG+doOSoxn5rDx4Gp0OHp7Wg+cWHeD91YlM6hXKoGi1jkpWQQlXf7SJY5kFdArw5I7xXWpso7+XKzeM6cx1o+JYfeg03287iaebgSuHRzMwKgCdrmpvR2VdQnz58oZz6vq1tHgOBR8PPfQQOTk59OjRA4PBQHl5Oc8++yyzZ88GIDVV/fJDQ23Ho0JDQy3HKluwYAFPPfVUfdouhBCiDVh96DRzPt7MOZ078s1NI+r8uvTcIq7/ZCu7T2XjZtDz/Iy+XDooEoAJPUN4+td9/LYrhY/XH63yWhe9jp/njaoSgHz61zEAzusewk1j4zmQksuP209x37c7+f3OMZRrGnMWbuFAai7Bvu58ecNwAutYLVSvV1NkW/s02cbgUPDx7bff8uWXX/LVV1/Ru3dvduzYwd13301ERARz5sypVwMefvhh5s+fb/k5JyeHqKioGl4hhBCiLVm2T/1xuvHIGXafzKZvZN2GSZ77XfVudPR24/2rBzM0tqPlWIivB29dOYhLB6Xx9eYTFFstIX/qbAGJp/OZ/+0Ofr1jNO4uargjt6iU77aeAODaUbEAPHFhb/5KzORIRj7//n0fCel57DyRRQcvV768YTixQd6N8RW0Ow4FH/fffz8PPfSQZfikb9++HD9+nAULFjBnzhzCwlTFtbS0NMLDwy2vS0tLY8CAAXav6e7ujrt789aYF0II0XzWJ2Ratj/56xivXNa/1tdomsYa05onb1050CbwsDa+Ryjje9j2xmfmFTPl9TUcSsvj9eWHLfkc3209SX5JOV1CfBhtyqvw93LlhX/2Y87Hm/lykyqf7uvuwmfXDadbqC+ifhya7VJQUIBeb/sSg8GA0agiyri4OMLCwlixYoXleE5ODps2bWLEiLp3pQkhhGgfTmUVcjQj3/LzrzuT67QmyuH0PM7kl+DhqmdIjP3AozqBPu48e0lfAN5fncjfSWcxGjU+3XAMgLkjY23yMM7tFmxZZ8XDVc/H1w6tc++MsM+hno8LL7yQZ599lujoaHr37s327dt59dVXue666wDQ6XTcfffd/Pvf/6Zr167ExcXx2GOPERERwT/+8Y+maL8QQohWbH2C6r0YGB0AwPakLL7enMSdE6pOXbW28YjqLRkS09GmKFddTekdxqUDO1nyOe6d3J3jmQX4ebhw6aBOVc5/fHovYgK9GBkfSL/IAIffT9hyKPh48803eeyxx7jttttIT08nIiKCm2++mccff9xyzgMPPEB+fj433XQTWVlZjB49msWLF+Ph0frnJQshhGhcf5mCj1HxQXQN9WF70g4+33icW86NrzGoMAcf53R2rNfDmnU+xz3f7gBg1rBovNyq3ho93Qzccm58lf2ifhyq8+EMUudDCCHaB03TGPbcCk7nFvP1jecwJLYDo1/4k7ScYv4zawAXD6jaA2F+3ZB/Lyczv4TvbxnBkGryPepi1cF05i7cAoBeB6vvP4+ojl71vl575sj9W9Z2EUII0SwOp+dxOrcYD1c9g2ICcDXouWp4DAAfrz9W7esS0vPINOV7NHQIZFz3EEs+x5TeYRJ4OIlDwy5CCCFETT5Yk8ha0ywUM1eDntvGxVfpoVhnOm9obEfLdNcrh0fz5soEdp7IYnvSWQaaCntZa2i+R2VPXdSbczp3tJQwF01Pgg8hhGjnSsqMPPHLHvp2CuDK4dH1vs6JMwU8t+iA3WNHTuexbP65uBoqgoW/Ek35HlblwgN93LmofwTfbzvJJ38dqyb4OAM0LN/DmpuLvtohHtE0ZNhFCCHaueX7VSGuR3/ezb7k+i9xsWh3CqDWK3nt8v68dnl/Xr2sP0E+bhzLLOC7rSct55aVGy1BxOhKa5XMHRkLwO+7UkjNtl2UVNM0q2TTwHq3VTQvCT6EEKKdW7E/HQCjBk/8sof6zkP4bZcKPmYNjeaSgZFcMjCSSwdFMu88tfbJf1YcoqhUrRC782Q2ecVlBHi50ivcNjmxTyd/hsV1pMyo8c6qBJtjjZnvIZqPBB9CCNGOlRs1Vh1UwYdOB1uOneV/O5Idvs6xjHx2n8rGoNcxrU+YzbErh0fTKcCTtJxiPjMV8jLX9xgZH2h3Gfl7JnYD4OvNSZywWgm2sfM9RPOQ35wQQrRjO09mkZlfgq+7C3dPUDf85xbtJ6+4zKHr/G4achkZH1hloTV3FwN3T1RFw95ZlUhOUalV8GF/efgR8YGM6RpEabnGa8sOWfY3dr6HaB4SfAghRDv2p2nIZWz3YG4Z15nYQC/Sc4t5c8Vhh65jHnK5oG+43eOXDoqkS4gPWQWlvLniMH8nnQWq5ntYe2CKWnPlpx2nOJiaK/kebYgEH0II0Y6tOKCCjwk9QnB3MfDEhb0B+GjdURLS8+p0jcTTeexPycFFr2NqpSEXM4Nex32TVc/Kh2uPUlqu0SnAk5jA6utq9I305/y+YWgavLz0oOR7tCESfAghRDuVnFXI/pQcdDpVbAvgvB4hTOwZQplR48lf9tYp+fS3narXY3TXIAK83Ko9b0rvMPpZLcg2qkugzQJu9syf1B29DpbtS+PdVYkADI7pIPkerZz89oQQog0pN2qcOFNg8ziVVYjRWDWIWGlKNB0U3YGO3hVBw2PTe+HmomddQgZvr0yoNQD5bZdKUJ3eL6LG83Q6HfdP6W75eVQNQy5mXUJ8+OfgSAB+3H4KgHPiZMiltZMiY0II0UasPXyaR3/ew/HMgirHzu8bxttXDrLpaTDne4zvEWJzbkygN3dP7MqLiw/y8tJDHM8s4NlL+trtbTiYmsvh9DzcDHom9QqttY2juwQxY1Ake5OzLb0ttblrYjd+3p5MSbkRgHPiJfho7ST4EEKIVi4zr5hnf99v6Rlw0etwMVQEGUWlRhbtTuXHv08xw9SLUFhSzjrTjJMJPasGAbeN64K3mwtP/bqX77ad5PiZAt67arBNDwnA76Zej7HdgvD3dK21rTqdjlcu6+/Q5+sU4Mnsc6JZuP6YKd/Dv/YXiRZNgg8hhGiljEaNH7ef4tnf93G2oBSdDuaMiOXeyd3w9agIBN5emcBLSw7y5K97GdklkHB/TzYcyaC4zEinAE+6h/ravf6ckbHEBHpxx1fb2Xz0DJe8s543rxhInwh/9HodmqZZZrnUNuTSUHeM78re5BxGxgda1oERrZcEH0II0cpkF5Ty3bYTfLbhOEmmAlw9wnxZcGlfu2uh3Dy2M0v3pbHzRBYPfL+Lz64bZqlqOr5HSI1Jn+O6h/DDbSO57pMtHM8s4KK31uPr4UL/yADigrw5kpGPu4ueiXUYcmmIjt5ufHvziCZ9D+E8EnwIIUQrkXg6j/+uPcJP209RVKryH/w8XLh1XBduGBNns2ibNReDnldm9ueCN9ay9nAGX25K4k/TFNvxdoZcKusW6sv/5o3ioR93s+bQaXKLyliXkGEZtjmvewg+7nI7EXWn0+pbxL+J5OTk4O/vT3Z2Nn5+frW/QAgh2oGE9Fwufms9+SVqbZQeYb7MHRnLxQM64elWt2GIj9Yd5Znf9uFq0FFaruHpamD745PwcK37MEZpuZGDqbnsPJnFzhNZJGcV8fD5PegdIXkY7Z0j928JVYUQooXLLSrlps+3kV9STv+oAB69oCdDYjrUWiOjsmtHxrJkbyqbj6oS5aO6BDkUeAC4GvT06eRPn07+zB4e49BrhTCTOh9CCOFkZ/NL+Hn7KcpMU0drYjRqzP92J0dO5xPu78FHc4YwNLajw4EHgF6v4+V/9sfL1FNSeYqtEM4iPR9CCOFEmqZx0+db2XLsLKeyCi3LzVfn3dWJLNuXhptBz7tXDSao0qJtjooO9OL9qwez8sBpLh3UqUHXEqK+pOdDCCGc6Ocdp9hyTC2q9ulfxyitofdj9aHTvLz0IABPX9ybAVEBjdKGMV2DefzCXg4PuQjRWCT4EEIIJ8ktKuW5RQcsP6fnFvPHnlS75544U8CdX29H0+CKYdHMGhbtrGYK0eQk+BBCCCd5Y8VhTucWExfkzW3j4gFYuP5olfM0TePhH3eTXVhK/6gAnryol7ObKkSTkuBDCCGcICE9l4XrjwHw+IW9mDsqFleDju1JWew4kWVz7uI9qaxLyMDNRc8bswZIRU/R5kjwIYQQdbRodwrP/r6P9Jwih16naRpP/rKPMqPGxJ6hnNc9hBBfDy40lST/9K9jlnMLS8r59+/7AbhlbGdiAr0brf1CtBQSfAghRB0kns7jrm+28+Hao0x4dTVfbjpud5l6e6x7Mh6fXjGEMndULKCWpDcHNO+uSuBUViGdAjy5dVzNM2GEaK0k+BBCiFqonou9lJZruLvoyS0q45Gf9nDZ+xs4nJZr9zWnc4tZsT+NV5ce5PFf9gJwy7nxRAd6Wc7pFxnA4JgOlJZrfLkpieOZ+by35ggAj17Qs86VS4VobaTOhxBC1GLpvjTWHs7AzaBn0V1jWH1QTYHdevws57+xlq4hvljX/MoqKOVUVqHNNaI7enHrufFVrj13ZCzbjp/ly03H2Xkyi5IyI6O7BDG1T1hTfywhmo0EH0IIUYOi0nKe/nUfADeN7Ux8sA/xwT5M6RPG4z/vYcWBdPal5FR5nU4HXYJ96B8VQP+oAC7oG263J2NqnzDC/DxIzSli1cHTuOh1PHlRr3pVMBWitZDgQwghavDuqkROZRUS4e/BbedV9Fx0CvDkv3OGsOdUDpn5xTav8XQ10CvCD18P11qv72rQc/WIGF5aooqJXTc6ji4hvo37IYRoYST4EEK0WtmFpdz42Vb6dvLnsen2a2EUl5Vz02fbSM4qpF9kAAOiAxgQGUD3MF/cXGpOe0vKLODd1YkAPHJBL7zcbP/J1Ol09I1s+GquVwyL5qN1R/F2N3DHeEkyFW2fBB9CiFbrm81JbD56hs1Hz3B+3zAGx3Sscs5Xm5JYfeg0AIfT8/jh75MAeLjquXZUHHdN6FptmfFnft9HSZmRkfGBnN+36XIwOnq7sfLecRgMOnzc5Z9l0fbJbBchhNPtOJHF0GeXc/VHm1i+L43yOk5ZtVZWbuSzDcctP7+4+CCaZnud/OIy3vozAYDrR8dx5/gujO0WjL+nK0WlRt5dlciU19ew7nCGzet2ncxi/v/tYNm+NFz0Op66qHeT52D4e7lK4CHaDfkvXQjhdK8vP8Tp3GJO5xaz9nAGkR08ueqcGC4bEkVHb7c6XWP5/jROZRXi7+lKYWk5m46eYc3hDM7tFmw55+N1R8nMLyE20IuHpvXA1aD+3tI0jWX70nj8f3s5nlnAVR9t4tKBnRgRH8iXm5JsKo7edl4XuoZKDoYQjUmnVf5ToZnl5OTg7+9PdnY2fn5+zd0cIUQjSzydx4RXVqPTwdXnxPDLzmSyCkoBNUOka4gP/SMD6BelcjP6dPKz2+tw2fsb2Hz0DPPOi6eo1MhH647Sp5Mfv8wbjV6v42x+CWNfXElucRn/mTWAiwdUXT4+t6iUV5Ye4tMNx7D+l9DNoGd6v3CuGRnbaCvJCtHWOXL/lp4PIYRTfWYqJT6hRwhPX9yHf53fk192JvPZhmPsOZXDobQ8DqXl8d02lZsxsWco7189GIO+IgDZm5zN5qNnMOh1XH2OWiPlm81J7DmVwx97UrmgXzjvrU4kt7iMnuF+ljLmlfl6uPLkRb25eEAEj/1vD2fzS7liWBSzhkUT5OPe5N+FEO2VBB9CCKfJKSrle1NQMXdkHAAergYuGxLFZUOiOJ1bzK6TWew8kcWOk9lsTMxk+f40Xl12kPun9LBcx7wWyrQ+YYT5ewBww5jO/GfFYV5ZdpAB0QF8Yjrn/ind0OtrztcYGN2B3+4Y08ifVghRHUk4FUI4zXdbT5JfUk7XEB9GdQmscjzY150JPUOZP7k7n103jJdm9gPg7ZWJLN6TCkBmXjE/70gG4NpRcZbX3jAmjg5erhw5nc+VH26kuMzIkJgOnNc9xAmfTAjhCAk+hBBOUW7ULD0Wc0fF1mn2yMUDOnH9aBVg3PvtDhLS8/hmywlKyoz0i/RnUHSA5VxfD1fmnadqZBzPLADggak9pFKoEC2QBB9CCKdYdTCdpDMF+Hm4cMnAqsmf1XloWg+Gx3Ukv6Scmz7fyuem6bVzR1YNYK46J4Zw0zDMuO7BDIurWvdDCNH8JPgQQjjFwvXHAFXNs3Kl0Jq4GvS8PXsQYX4eHDmdT2pOEUE+7lzQL7zKuR6uBl76Z3/O6x7Mkxf2bqymCyEamQQfQogmdzgtl3UJGeh1qnfCUUE+7rx39WDcTHU6Zg+Pxt3FflXS0V2DWHjtMGKDvBvUZiFE03Eo+IiNVd2clR/z5s0DYNy4cVWO3XLLLU3ScCFEy6dpGscz83l9xWEAJvUKJaqjV72uNSAqgHdmD+KyIZFcPyau9hcIIVosh6babtmyhfLycsvPe/bsYdKkScycOdOy78Ybb+Tpp5+2/OzlVb9/aIQQzpWUWcCqQ+l0CfGhbyf/Oq3ICrBifxr7km2XlC8sLWdvcg47T2ZZCoiB7eyU+pjYK5SJvUIbdA0hRPNzKPgIDg62+fn5558nPj6ec88917LPy8uLsLCmW4BJCNE05n+7g63HzwKq0miXYB/6RwVwxbBoBsd0sPuabcfPcv2nW2u8rptBT68IPyb1CmW4JIAKIWhAkbGSkhK++OIL5s+fb5Nx/uWXX/LFF18QFhbGhRdeyGOPPVZj70dxcTHFxcWWn3Nycqo9VwjRNFKziyyBR6cAT05lFXI4PY/D6Xn8viuFRXeNIa5SDkW5UeOJX/YAMCg6gO5hFeWUDXroHupL/6gAeoT51bp0vRCifal38PHzzz+TlZXF3LlzLfuuvPJKYmJiiIiIYNeuXTz44IMcPHiQH3/8sdrrLFiwgKeeeqq+zRBCNIJl+1QBr0HRAfx42yhLpdF3ViWy7fhZ7vtuJ9/ePMKmxPk3W1Q5c18PFz64ZoiUIxdC1Fm9F5abMmUKbm5u/Prrr9We8+effzJhwgQSEhKIj4+3e469no+oqChZWE4IJ7rqv5tYl5DBw9N6cPO5Ff+vnjxbwNTX15JXXMa/zu/BTWPVsbP5JZz3yiqyCkp58sJezG1gLocQovVzZGG5evWFHj9+nOXLl3PDDTfUeN7w4cMBSEhIqPYcd3d3/Pz8bB5CCOfJLihl45FMAKb0ts3XiuzgxWPTewLw8tJDHE7LNW0fJKuglB5hvvWaOiuEaN/qFXwsXLiQkJAQLrjgghrP27FjBwDh4VWLAQkhWoYVB9IoM2p0D/W1WxvjsiFRnNc9mJIyI/d+t5PtSWf5anMSAE9d1BsXg+RzCCEc43DOh9FoZOHChcyZMwcXl4qXJyYm8tVXX3H++ecTGBjIrl27uOeeexg7diz9+vVr1EYLIRrPkr0q32NKb/tTWHU6Hc/P6Mfk19aw62Q2V/13E5oGFw+IYHjnqovDCSGsHFkFWz+GaS+BbyNPE9/0Aez5ofbzfMPg4rfA3bdx378BHA4+li9fTlJSEtddd53Nfjc3N5YvX87rr79Ofn4+UVFRzJgxg0cffbTRGiuEaFyFJeWsPnQagMm9q58iH+rnwVMX9ebu/9tBfkk53m4G/nV+T2c1U4jWqfAsfH8dFGRCYFeY8FjjXbs4D5Y+AuUldTu/8zgYcm3jvX8DORx8TJ48GXs5qlFRUaxevbpRGiWEcI41h09TVGqkU4AnvSNqzre6eEAEy/al8fvuFO6Z1I1QPw8ntVKIVmrlcyrwADi0pHGDjyOrVODhHw1Tnq3+vENLYMcX6rk1Bx9CiLajYsglrNal53U6Ha/PGsCt4+JrDVSEaPdSd8OW/1b8nLYbsk+Cf2TjXP/QYvXc4wLodVH153WMU8HHkVVQWgiuno3z/g0kmWJCtFOl5UZW7E8Hqs/3qMzVoKdPJ/9aAxUh2jVNg0UPgGaE3pdAlJr5yaEljXN9oxEOL1Xb3abUfG5oH/DrBGWFcHRt47x/I5DgQ4h2avPRM2QXltLR240hsVL2XIhGs/t7SPoLXL1g8r8rAgRzwNBQKTsgLw3cfCBmVM3n6nQV72/uLWkBJPgQog0rLCnn/7YkceGb6zjnuRU8t2g/SZkFQMWQy8SeITaVS4UQDVCcC0tNEy3G3KuGWbpNVT8fWQUlBQ1/D3MPSvx4cHGr/Xzz+x9aonplWgDJ+RCiDUrKLOCLTcf5vy0nyC6sWFX2gzVH+HDtEcZ3D2HXqWygamExIUQDrH4R8lKhY2cYeYfaF9IL/KMg+wQcW1v7UAmA0bSCvN5Q9Zi5B8McVNQmbiy4eELOSUjbC2F96va6JiQ9H0K0Mcv3pTH+lVV8sOYI2YWlRHbw5OFpPXjvqsGM6RqEpsGKA+mczi3G283AqC5Bzd1kIdqG04dg4ztqe+rz4GJa78jRoY+SAnhvDLw1BAqzbI/lpKhhF4Cuk+rWLldPFYAAHG6kvJMGkp4PIdqQjLxiHvxhF2VGjeFxHblpbGfGda8YVpnaJ4wjp/P4fONx/tidyuVDo/BwtfOXlRDCMZoGf9wPxjLoOqVq70a3qWr2i3noo6ak7XWvQfpetb3qeZj2fMUxc95Ip8HgE1L39nWbogKPQ0vUcFAzk+BDiDZC0zQe/WkPmfkl9Ajz5bPrh+HuUjWw6BzswxMX9uaJC3s3QyuFaKP2/6pyOgxutsGCWewYlYCacwrS9kBYX/vXOXMU1v+n4ufNH8CgayC0l/rZnO9R1yEXs25T4HfgxGbIzwTv5q1OLMMuQrQRv+xMZvHeVFz0Ol65rL/dwEMI0QRKCmDJI2p71F0q36MyVw9VZRRqHnpZ8i8oL1bn9pgOWjn88YDqLSktUgEO1C1vxJp/JIT2BTRIWObYa5uABB9CtAFpOUU89vMeAO6c0JXeEf7N3CIh2pH1r0N2kkoqHT2/+vMseR/V5F0cWgoHF4HeBaa9CFOeAxcPlaS690c4vg5K88E3HMLqsWZaC5pyK8GHEK2cpmk89MMucorK6NvJn1vHxTd3k4RoP84chXWvq+0pz4KbV/Xndp2snk9uhfwM22NlxbD4QbV9zq0Q3B06xFQEM0sfgz0/qu1uU2rOGamOeagmYQWUl9Z8bhOT4EOIVu7/tpxg5cHTuLnoeeWy/rjKEvdCOI95mCTuXOhZQ5lzAL8ICO8PaHC40tDHhrfgzBHwCYOxD1TsH3UnBMSoXJEdX6p9juZ7mHUaBF5BUJwDSRvqd41GIgmnQrRS+cVlvLL0EJ/8dRSAeyd1o1toy1kyW4gWK22fChgiBtb9NUYj7P8FCs9U7MtNtR0mqUtvRLepkLITtn2iSp6Dqumx5mW1Pelp8LBaO8nVU03b/eYK9bOLhwp06kNvUL0vO79SQz/m6bfNQIIPIVqwTUcySc0pol9kALGBXpY1Vf48kMajP+0hObsIgH8OjuSGMXaS3IQQtkry4eMp6vnm1dXPOqls8wcVwyKVDb8FQnrU7TrdpsDqF+DERvWwFj0C+l1W9TXdp0GXSSpRNHZMzUM7dXn/nV+pvI+aVsNtYhJ8CNFCHUzN5YoPN2I0VUP293SlX6Q/LnodKw+eBiCygyfPXtKXc7sFN2NLhWhFjqxSww6gFn+7dlHtPRZ56bDSdKOOHQMeVgndPiEw7uG6v3/EIBj3L0jdZbvf1VNdx15bdDq46E1Y+woMua7u72VP/HgIHwBdJqq8D4Nrw65XTxJ8COFkOUWl7D6Zzd7kbPpHBjC8s/359i8vPYhRgyAfd3KLSskuLGXtYZWkZtDruGF0HHdN7IqXm/xvLESdWc/0SPpLLQLXb2bNr1n+lApYwgfANf+zX/K8rnQ6GFdND0pN/MLhgpfr/75mHn6qx6eZyb9aQjhBQnou76xMZMfJLI6czrfs93DVs+jOMXQO9rE5/++ksyzbl4ZeB9/cdA4xgV4cTM1lx4kskrMKOb9vOH06yXRaIRyiaWo6K6g6GkdWqUXguk8F92rypU5sgR1fqO3zX25Y4CEsJC1eiAZadziDd1clUlputHu8oKSMaz7azI/bT1kCj6iOnsQEelFUauS+73ZSbqxYaVLTNF5afBCAGYMi6RLig6tBT59O/lx1TgwPTO0hgYcQ9ZGyUy365uoNl32uioHlpcKal+yfbyyHRfep7QGzIWqo89raxknPhxANkJpdxE2fb6WgpJzisnLuntityjnvrEwkObuITgGe/PsffegX6U+gjzunsgqZ+toa/k7K4sO1R7jlXFWfY11CBhuOZOJm0HP3pKrXE0LUk2Up+vPU8MPU5+Gry2DDOzDgKgiu9P/b9s/VIm7ufjDxSWe3tk2Tng8hGuC5RfspKFFLX7/1ZwJ7TMvUmx3LyOeDNUcAeGx6L87rEUKgj1rpslOAJ49dqNZreHXpIQ6l5apejyWq12P2OdF0CvB01kcRou2rvBR9tylq21iqZrJoFT2QFJxRuR4A5/3LsUXcRK2k50OIetp4JJNfdiaj08Gg6A5sO36W+d/u4Nc7RlvWVXnmt32UlBsZ0zWIKb1Dq1xj5uBIluxJZcWBdOZ/u4Obx8az62Q2Xm4G5p3XxdkfSYiWY9//4O/PQLMeztTBgCuh7z/tv0bT1Cqwnh3gnFtsj+WmQfLfattcaRRg6gJI/FM9PrkAXNxN56eqmh4hvWDojY32sYQiwYcQ9VBWbuTJX9SS11cOi2b+pG5Mfm0Nh9LyeH35YR6c2oMV+9NYcSAdV4OOJy/qbanRYU2n07Hg0r5Mem0Ne07lcO+3OwG4YXQcQaYeEiHanexT8NOtah2TylJ2Qp8Z9qeknj4Aq00ryob2hrgxFcfMS9FHDAJfqz8EOnaGUXfDmhfh+Pqq15z2IhjkVtnY5BsVoh6+2HicA6m5BHi5ct/k7nTwduO5S/ty8+fbeH91ImO7BvP0b/sAuG50HPGVZrNYC/Hz4OmLe3PXNzsoKTcS4OXKDWOlYJhox5Y9pgKPToNh2M2mnRr8fBsUZKhS4/6RVV+XvL1i+48H4OY1FXUsKg+5WBv3kCp7XlIp2OkQA9HnNPjjiKok+BDCQRl5xbyy7BAA909RgQfAlN5hXDKwEz9tP8WcjzdTUm4k1M+dO8Z3rfWaF/WPYNm+NH7blcKd47vi59E8hX+EaHZH18KeHwAdTH/NtBaKyV9vQtoe1fthL/hI2Vmxnb4PtvxXLdJWVgyJK9X+bpOrvk5vgJ7TG/VjiJpJwqkQJpuPnuGSd9bz7dYTNZ734uID5BaV0aeTH7OGRtsce/LC3oT6uVNimnb7r/N74uNee4yv0+l4/fIB/Hr7aK4dFVvvzyBEq1ZepnosQFXytA48QBX5AkjeYf/15v2xpuGWlc+p6qTHTEvR+4RBWH/7rxVOJcGHEEBWQQm3f/U325OyeOD7XTz7+z6b2hsARqPGFxuP8+3WkwA8dVEfDHrbcWd/L1de/Gd/XPQ6xnQN4qL+EXVug4tBT99If7u5IUK0C1v+q3osPDvC+EerHjcHI9Y9HGbG8oqS5dNeVIFKcY6asWKeYtttMujlttcSyLCLaHOyC0uZ/d+NRHXw4rXLB+DhWntFwid/2Ut6bjEdvFw5W1DKh2uPcjQjn//MGoi3uwsJ6bk8/ONuthw7C8AVw6IYHNPB7rXO7RbMXw+Nx9/LVQIJIerKev2UCY+DV8eq50QMUM8pO6oey0yA0gJVQCy4u6pG+tFEVZ3UvBZLfZeiF41Ogg/R5nz61zH2nMphz6kcSsu38+5Vg3A1VP/XzuI9Kfy8Ixm9Dj6eO5QTZwu577udLN+fzj/f28D4HsF8uOYoJeVGvNwMzJ/UjbkjY2tsQ4ifRyN/qnZC0+q2LHlbff/2zLJ+Sn8YdI39c0L7gE4PeWmQk6LWOzEzD7mE9VU5HFFDVeGwHV9AUTYY3Ou/FL1odNL/JNqUgpIyFq4/avl5+f407v12Z5UhFLPMvGIe+WkPALecG8/A6A5c1D+Cb246hyAfd/an5PD2ykRKyo2M7xHC0nvGcsOYzrjUEMyIevp5HrzWB84ea573/+Kf8M4IKDzbPO/fGu3/DRZEVayXUl8pu+q2foqbFwR1N72m0tCLuTfEOk9k4hOqOimoabfu1c86E84l/4KKNuXrzSc4W1BKTKAXH1w9GBe9jl92JvPIT7vRNNsARNM0HvlpD5n5JfQI8+WuiRWzUgZFd+B/t4+if6Q/YX4evHXlQD6aM4TIDl7O/kjtQ8EZ2PkV5JyExf9qnvdPWAan98PKBc5//9Zq03uqt2LX/zXsOnt/VM89L4SoYTWfW93QizkYMR8HVZV02gvg5gNDb2hYG0WjkmEX0aKczS/B39MVvd7xru/isnI+NJUyv+XceCb3DuO1ywdw1zfb+WbLCTzdDFw5rGJ2ysajZ1i8NxUXvY6XZ/a3VCU16xTgyc/zRgFI7kZTS1heUcny4O9weDl0nei89z9zpGJ7y4eq2z+sj/PevzUqzILjf6ltezkYjjAnhPb6R+3nhveHnV/b9nwYjar3BCpmxJgNuBL6XyHDaS2MBB+ixfhu6wke/GEX142K49HpvRx+/c/bT5GaU0SonzuXDuoEwIX9IygsLeeB73excP0xFq4/VuV1d4zvWu0qsRJ0OIm5AJRnBzXs8ccDELehotR1U8tMqNjWjOr95/4uN6yaJK4ATa1rRGYCFOWoxdocdfa4muGiM0D8+NrPtzfd9kwilOSCiycE2VmMUX6PLY4Mu4gWYeeJLB75aQ9GDf5v6wmKy8oden25UeO91eqv1xtGd7bpxbhsSBTPX9qXCH8POnq72Twm9QrltvPiG/WzCAeVl6qeD4BL/wveIepmsvEd57XBHHx0maRuYMfXmwpdiWqZeyvMUnfX7zrmsufR59if4VJZWF9AB7nJaoYMVPSChPWRUuithPyWRLPLyCvmli+2WQpz5RaVsfZQBhN7VV2IrTp/7EnhaEY+/p6uXDk8usrxWcOimTWs6n7RApzYpGYjeHZUS51PfgZ+uhlWvwR9LwP/Tk3fBnPw0XkcRA2Hlf+GpY+qVU/dfZv+/VsbYzkcXqa2fcMhN0UNvcSOcvxa5l6vrnYqj9rj7gNBXSHjkAo6uk6qKKteuSiZaLGk50M0q7JyI3d8tZ2U7CI6B3nzz8GqZPLvu1PqfA1N03h7ZSIAc0fG4l2HiqKiBbG++egN0O9yiDpHVaRc9phz2mAOPgK7wMg7oEOsuqGueck579/anNyqVnz18IdBc9S+6qqO1qQ4D46uUduO1OCoPPRi7vmonO8hWiz5V1o0qxcWH2DDkUy83Qy8f/VgcopK+X7bSZbtS6OotLxOBcJWHTrN/pQcvNwMtdbfEM3kzBEoLVQrjVZmnqbZbYp61ung/Bfh/XPV0Mfga21XJ60sZSd4B4NfDdVkTx8Egxt0jKt6TNMgUwWvBHYBVw+Y+gJ8fTlseEcFIq5Ws5w6xDbfYmOZiWqdklDHc6Js5J2GI6sqcjbMYkZCQB16CM0BY5dJavE3sF91tDZHV0N5CQTEqMJgdRUxAHZ/q3pbjEb7M11EiybBh2g2v+5M5sO1qibHyzP70zXUF6NRI8Lfg+TsIlYdPM3UPmG1XufjdeoaVw6LtizyJloQYzl8PE2tRnrjSgjvV3HszBHIOAh6F9tkw/D+am2PrR+ppc6rCz4yE+HD8SpouG2j/cTCvHT44DzVXX/Pvqo5AbkpqjKmzqBWMQXoPlX1xBxeCr/dU/Wa8zY7drNsDKVF8NEkNUR18xr7gVxd/XyrmlpcmV8n9dlqq4dhKVc+teKGn3FI9WQ4UkvDeqVZR5JCrcusnz2qpvsa3CG4R92vIZqVDLuIZpFTVMq/flIJarecG8+0vqpSoV6v44J+avu3Xcm1Xiczr5i/EjMBuOqcmCZqrWiQzATISwVjGSy6X/U0mJl7PaJHgGeA7evMdRlO/a3+urXn+Hp13dMH1MOew0vVEE5emgp07LUPVI+GwWo14emvQa+LIX5CxcM7RB1L2lDTJ24ax9dBQabpe3zA9nt0hNFY0f6Y0RWfzStILVW/9pWaX5+VBOl7VaXRLhNULQ3fcEBTK8460o7KvV51FWYKYLNPQOKfaju0t+3vT7RoEnyIZvH5huPkFpXRNcSH+6fY/gV5QT/Vfb5ifzqFJTXPevljTyrlRo2+nfyJDfJusvaKBrDujj+xEXZ9W/Gz9V++lQV1UzNPSvLU7Jfarm2+VmXW++0NDVjne1jzj4TLPoOrf6x4DLiy+us0NevZJcfX1X82zplE9Z26eMI1/6v4bBe9qY7/9SZkJFT/enM7oqxmp9S22qw9qTtVUOrqDbGjHfsMHn7Q0TRL7e9PTW2QZNPWRIIP4XRFpeWWEui3jouvsjJs/0h/ojp6Ulhazp8H0mu8lrl3ZHq/8BrPE83IfEPyNN2olj2makIU56qlzsH+X74GF9O0SmpfQh2qTv0ElR+RuNL++WbW+R61Md/g6pNc2RCaVhFERY9Uz0sfVcMcjrKsgVJpWmr3aSqHw1gKix+qvmfFMuRi9TuracG36pivE39e/eq5mN/TPMVX8j1aFQk+RIOdPFvAW38eJj2nqE7nf7v1BBl5JUR28ORCO0vO63Q6Luir9tc09JKeU8Smo2cALEM1ogUy9xJMeFz9tZqXBqtfUEGBsRQ6dq7+xl/TTa28zLab/8QmVSbd2vH16q/8ym2xZun5qEO9F3N70vaq+iTOcvqAGu5w8YBZXzZsNo5lDZQBtvt1Opj6POhdVT6IvZ6kknz7s1NqWuq+OjX1etVF5fbLTJdWxaHgIzY2Fp1OV+Uxb948AIqKipg3bx6BgYH4+PgwY8YM0tLSmqThouV46td9vLz0EBe/vZ69ydk1nltabuR9UzGwm8d2rna1WXNPxp8H0skrLrN7zqLdKWgaDIgKkDVXWirrmQhRw9Q6G6DWBNn4rtquKdmwpptaxkEoKwI3XwjprSqTmouVmVkPEQCk7lIJsNaqG3axp0McuPtDeXH1OSZNwXyjjhurhjqmPq9+3vA2ZBx27Fo1zQwJ6gIjb1fbfzyoklytHVmtPnvl2SnmG//pA1BSUHsbclMranPUtb5HZdbDLHpXCOlZv+uIZuFQ8LFlyxZSUlIsj2XLVLb0zJkzAbjnnnv49ddf+e6771i9ejXJyclceumljd9q0WKcyS9hpWloJCW7iJnvbWDp3tRqz/9lRzKnsgoJ8nFn5pCoas/rHeFHbKAXxWVGVuy3H8Caa4HIkEsLduaIqey1h1qNtOsk6H6+SppMMq0LUlOyofmmlrKzatKppbZDPzU7BWz/Wtc0OPiH2h4xT+UWlBbY3qzLSytW0a1L8KHTVczWcebQS+Whjm6m2TjGUhUk1DX51DoYrC5HYsx94BsBWcfhrzcqtaOa2Sm+YSoZVzOqXqHamKuaRgwC37oXE7Rh3f7QXs4rxS8ahUPBR3BwMGFhYZbHb7/9Rnx8POeeey7Z2dl89NFHvPrqq4wfP57BgwezcOFC/vrrLzZu3NhU7RfN7LddyZQZNXqE+TKmaxAFJeXc/MU23l+dWGUVWaNR493Vanz9+tFxNdbw0Ol0TO9nHnqpWnAsJbuQLcfU0ucy5NKCmbv4Q63yC6Y8p6ZFguq1MOcw2BPcXZ1bnKOmVFoz3/zDB1R03ScsrxgOyTikbqAGdzWN1xw0WPeiZCWpQMjVyzRjow4sQ0FOSjotOKOGlAC6WtVCmfq8ql2SuAK+mAHfzK54LH20ag8P1G1aqruPqjILauaL9XX3/qz2Vw4Ydbrqh8hykuHHm2yvs+Zl03XqOeQCanZUB1PdFhlyaXXqnfNRUlLCF198wXXXXYdOp2Pbtm2UlpYycWLFSpQ9evQgOjqaDRuqn5ZWXFxMTk6OzUO0HMv3pTH//3ZwJr/E7vEf/j4FwMwhUXw8dyhXnRONpsGCPw5w+9fb2Z9S8ftcui+NhPQ8fD1cuOqc2gsZTe+vbgarD57mbKX3/90UkAyN7UC4v2e9PptwAvONyLqLv2McjDbVzug+DVxqqM1icK1YXbbKEuqmn8P7q0JXXoGqBob5Rm0ZqhijbqiWIRyr65iHXDrGg76O/xxaemN21HRW4zGv+BvSGwKsegsD42GEaYgkcQUc+K3i8debkLCi6rXMbQ7rU/O01D4zIHaMGtayvm5xNngE2J+dUt2Ml9/ugV3/Z3udrOPqWI8Lav/8NTG3I7aGInSiRap3kbGff/6ZrKws5s6dC0Bqaipubm4EBATYnBcaGkpqavXd8AsWLOCpp56qbzNEE1q6N5Vbv/ybcqOGh5uB5y7pa3M88XQeO09kYdDruKh/BK4GPc9c3IcuwT48/ds+ft+Vwu+7UhgW15E5I2L5YI3q9ZgzIhZfj9rn43cP9aVHmC8HUnO54bOtfH79MLzc1H+y5t6QC/pKr0eLVl0X/7kPqoAhamjt1wgfAKe2qZtanxlqn7HcdpaD3qCGIXZ+rYKO2NFWNSSmVlwHbG+OlnyPznX/TObrpO5RSa9NvZCZvdklZuc9oupbFOdW7DvwmwpYDi2GbpXyKWobcjHT6dQ04wO/q54ha1HD7Q9x2MvPObREtUPvCpP/bfu6jnEVgWV9Tf439P6HqlMiWpV6/1/z0UcfMW3aNCIiaihpXAcPP/ww8+fPt/yck5NDVFT1uQDCOdYePs3tX22n3KiGTr7dcoKbxnS2qaXx83bV6zG2axDBvuofFZ1Ox9xRcfSPCuC/a4+yeG8qm4+eYbNpVoqHq55rR8XWqQ06nY7XLh/A5e9vYNvxs9z42VY+mjOU07nF7DiRpapwS/DRcmla9Wtu6PVVb4zVsXdTyzis8jdcvStyNbpNMQUfS2DMvRWFtMwJjebrpO5SuQ96vWPJpmYdO6vhopJcNbTT0FLnNSkvq6hEam+IwuACff9pu8+vkyn4WKJ+B9a5GdZDVbXx6giDrq57W829W6f3VySq/vGgej7nVjjnlrpfq648A6DLxFpPEy1PvYZdjh8/zvLly7nhhhss+8LCwigpKSErK8vm3LS0NMLCqi+R7e7ujp+fn81DNK8tx85w02dqldlpfcIY2y2YMqPGq8sOWc4xGjV+NA25XDoosso1BkZ34O3Zg1j/4HjuHN+FIB/VtT5nRCyBPnVPDOsZ7sen1w3D283A+oRMbv9qO7/sVNNvh8d1JMTPoyEfVTSls8fUMIjBrWFlr61zLMx5RJYl1PuqXg9QeR16FxUQbP6vWrckuGdFyXR7RcvqE3zo9Vb5Izvq+6nqxnrF38ghdXtN3Bj1OXNO2iZ/2gSDTVCQy6+TGvoylqn33fCWyjHxCYNzH2j89xOtWr2Cj4ULFxISEsIFF1SM1w0ePBhXV1dWrKgYZzx48CBJSUmMGDGi4S0VTrH7ZDbXLdxCYWk553YL5j+zBvKAqQLpLzuT2Zescji2HDvDqaxCfN1dmNSr+mz1MH8P5k/uzvqHxvPr7aN5YKrjN6GB0R3475yhuLvoWb4/jVeWqhLZ5oRU0UJZkk1715zXUZvgniqAKcqqmJliL5fEw18tjAYVJcKthyoMLlb5I6absCMFxqxZz8JpSpVX/K0LV0/oPM729aDyLIqy1HcZ0gS9NTpdxfdy4LeKpNLJ/wZ338Z/P9GqORx8GI1GFi5cyJw5c3BxqRi18ff35/rrr2f+/PmsXLmSbdu2ce211zJixAjOOaeZVoAUDjmclss1H28it7iMYXEdee+qwbi56OnTyd8ynfVl043f3OsxrW9YnVaedXcx0DfSv0o107oaER/Ie1cNxkWvw6iBXkedFp0TzcjSxd/Av7JdrG6W5pt9dcMH5qGJskLbn80seR/bVcGsHPXfsePBh5MqndaU71ET8/nWVV/NbQ3p1bBgsCbmYHDda+p3ED2y6rCQENQj+Fi+fDlJSUlcd911VY699tprTJ8+nRkzZjB27FjCwsL48ccfG6Whomkdz8xn9n83cbaglP6R/nw0ZwiebhVBxb2Tu2PQ6/jzQDrrDmewyFRjw96QS1M5r0cI/5k1EFeDjml9wglyYPhG1JOm2X/URXX5HvVhPY3TaFR5G1A1sOlqdZP27ACRlRJarYdwzhypOM+8Romj7bFXtAyq/94ceVS34m9dmPNcTm6B/IyKzwxNuwaK5dqaWnju/BcdW61WtBsOJ5xOnjy5Sv0GMw8PD95++23efvvtBjdMOE9yViFXfriJ9Nxiuof68sm1w6rMRokL8uayIZF8vfkEt325jdziMjoFeDIs1sF/tBvogn7hjO4ShI9HE88waOuykmDhBWqmgLmmQ2W5qfDR5IppkWauXjDrK7UmR3U0zf7QSH1Z9zRYL4wW1M32vKAuatrsmUS1TknlmSjWyasZphwmR3s9zK9x9Var5WYm2Fb7XPoo/PUWUM9VZyuzt+Jvbfw7qXyY1N0q+bT/rMb9fVTHOtAcekPF2jxCVCJru7Rzp3OLueq/mziVVUhckDef3zCMDt72u2TvnNAVNxc9OUVq6t0lAzuhr+cwSkP4e7nWe/hGmOz8P8hOUhUsk6opArjsiaqBB6hZJr/dU7X0trXsE1B41lT2uhHyC6xzLKpbGM1s+M2qiNaQa6seC+5RUbTMXAejPsGH3mB/0buTW1WNjcYKPHR6GDSnfq81DzkdWqyCQUdmutRXQLQqZR/YBc77V9O9j2j15M/HdiyroISrP9rEkYx8OgV48sUNwwnxrX72SLi/J3NGxPDhWlVp8pJBnZzVVNHYrBMRF90HN622TWg8vgF2fQPoYO5vKukTVNGp/05Qsxg2vAlj77d/fUt+Qc/GKXsd0ksNPxSeUcmMUP1NdPjN6mGPwVUlwCb/DftN16nLgnL2RAyAExtVj0L/y9Xwy+/3qmP9ZqlKrg3l4lb/ZM1uU9XCcwkr1O+r8Iz6Dpsi2dRMp4Prl6jvoq4JsqJdkuCjnUrJLuT6T7ZyIDWXIB93vrhhOJ0Caq8Ueuu4Lqw9nEHPcD/ig32c0FLR6PLSVdEuAHc/1TW/baHqJgd141hkCioGXVO1muXkf8MP18OaV9RNNsBOXR7r6qONwdVDBTKpu1XhK6j/8EHEABV8FJsWQaxPzwdUrT+y/XP1ud39YNLT4B1Yv+s2lohB4BUEBRmw8T21L6Sn+i6bmgQeohYy7NIO7TqZxcVvrWdfSg6B3m58ecNw4qyKh9Wko7cbi+8ey2uXD2jaRoqmc3gZoKmb54TH1b4Vz0B+ptre+jGk7VZltCc8UfX1fWZAzCg1m2HpI/bfo6aVU+vL3NNhNK3dUt/ApnKPSb2DD9N1Unap9VeWmyo1j3u4/oulNSa9vmLWy7ZP1HNTJpsK4QAJPtqZRbtTuOz9DaTnFtMt1Ief542ie5jMwW9XrFcmHXwthPZV9R/+fFrNjPjTlIA6/lH7f73rdDDtRdAZYN//IHGl7fGmyi+wvnHWtDCaI9cBVbG0PixFy3LhhxvUsEZwTxh2Y/2u1xTMwUd5sXqWBdhECyHBRzuhaRpvr0zgti//pqjUyLjuwfxw60iiOno1d9OEM5WVVAQL3aaohM3zX1I/b/sUvpurKmqG9YUhVafTW4T1qbjJ/vGAuq5ZTrLq6tcZVH5FY4kYaPv+NS2MVpOQXioRFlRVTre69fpVYV20LNGUvHr+i/VvV1PofF7FZwXb71CIZiTBRzuxaHcqLy1RBcLmjozlv9cMqdPibqIVyD4Jpw/Vfh5A0l/qL3XvEAg33YhiRkC/ywENjq1V+85/ufZx+3EPq5yCjEOw7DHVC7Lvfyp/BEz5BY244nBobxXQQMOGD1zcKtZjqW+vh5l1O3pfCnFjG3a9xubhV1H1tbGDQSEaQIKPduKbLUkAXD86jicv6o2LQX71bUJ+Jrw/Ft4dabuOR3UsFTMn2y4hP+lpcDMlEPebBdF1qErsGQCTTHkOm96Db69RjzWmnpTGzi9w9VQBDTR8+MDcAxDUtXGu4+qlEnFbIvOU2+AejRsMCtEAMtulHUjLKWJ9gqpyeM2ImGZujWhUfz4NBaZE0UUPqGmx1VWU1DQ4+Ifa7lqpXLdvGFzyHuz9GaY8W/f373+lmoGSsst2v6snnHNb3a9TV5Oegr0/Nbxk96i7oTgPRtzesOv0+gccXQM9L1SFvVqiQVdD+l7VViFaCJ1WXbnSZpKTk4O/vz/Z2dmywm0j+WBNIs8tOsCQmA58f+vI5m6OaCyn/oYPxwOaWiysvARmfFT9jTnjMLw1ROUAPHhUFvsSQjQqR+7f0vfeDpgXgZOiYG2I0WiqxaGpfI2xpiXLlz6q/qK3xzzLJXa0BB5CiGYlwUcbty85hwOpubgZ9EzvK0vQtxk7v4ZTW1WexqSnYeQd0CEWclMqci4qs+R7TLV/XAghnESCjzbux79PAjChZwj+XjK7pU0ozILlpuJf5z6o8jVcPWDq82rfhrfVEEvl1xz/S213m+yslgohhF0SfLRhZeVG/rczGYBLB0U2c2tEo1n1POSfVkWuht9Ssb/bVLWUurEU/nhQJZiaJa4ArRyCujd8eqkQQjSQzHZpw9YnZnI6t5gOXq6c2y24uZsjGkPaPtj8gdqe9oKqWWGm06nejyOrVLDxzWxwMxWRM5c771ZplosQQjQDCT7aMPOQy0X9I3BzkU6uVk/TVJKpVq6mdsaPr3pOYLzK/1j7Chz8verxHtObvp1CCFELCT7aqLziMpbsTQXgEhlyaRv2/gjH16n1RGparn3cwyr5tDjXdn9ANEQPb9ImCiFEXUjw0Ub9sTuFolIjnYO96R/p39zNEQ1VnAdLHlXbY+5VgUR1DK4w6BrntEsIIepB+uLbqJ+2q9oelw7shK66ipei9Vj7MuQmqx6NkXc0d2uEEKJBJPhog9JyithwRJXcvniAFBZr9TIS4K+31PbU59W0WiGEaMUk+GiD/tidgqbBoOgAojp6NXdzRENomlqy3liqptFKgTAhRBsgwUcb9NuuFACm95OKpq3ewUVq2qzBTfV6yBCaEKINkOCjjUnOKmTr8bPodHB+3/Dmbk7zKC2Eheeb1j5pBnmn1TL3699o2HVKC2Hxw2p75B1qGq0QQrQBEny0MYt2q16PoTEdCfNvp7kBJ7fC8fWw+UPIS3f++x/4TRX12vpRw66z/g3IOg5+ndQMFyGEaCMk+GhjLEMu/dtprwdAZoJpQ4PDy5z//ik71HNWEpQV1+8aZ4/DulfV9pRnwc27UZomhBAtgQQfbciJMwXsOJGFXgdT+4Q1d3OajyX4oGIZeWdK3qGeNSOcPVa/ayz5F5QVQewY6PWPRmqYEEK0DBJ8tCG/m4ZchscFEuLbTodcADITK7YT/4SyEue9d1kJpO+zaktC9edWJ2G5GrrRGeD8lyTJVAjR5kjw0Yb8tkutYNuuh1zA9oZfkqfyP5zl9H4otwp2HA0+ykrUirSgVqwN6dl4bRNCiBZCgo824lhGPntO5WDQ65jaux0PuZSXwdmjarvzeer50BLnvb959VgzR4OPTe+q13iHwLgHG69dQgjRgkjw0ZxKCyF1jyok1UDmIZeR8YEE+rhDfiZknWjwdVudrONgLFOLrw25Vu07tLhRvuM6Med7+JpqrFgPAdUmJxlWv6i2Jz0NHrImjxCibZLgozktuh/eGwVHVjX4Ur/uNA259AsHoxEWToV3RqiaE+2J+WYfGK+WnDe4qZ6Q+uRe1Id5pkufS03tceB9lz2uhomihkO/yxu9aUII0VJI8NGcTm5Rz2l76n2JcqPGX4kZHEjNxUWvY0rvMHUDzDgEJblwYlPjtLW1MN/sA+PB3RdiR6ufnTHrpbxU9WQB9JmhnvPSoCin9tceWw+7vwN0MO1F0Mv/mkKItsuluRvQbhnL4cwRtZ2b6tBLd5/M5rfdyew8kcXuk9nkl5QDMKZrEAFebrDJKschZSf0nN5YrW75LMFHF/Xcbaqa8XJoSdOvBnv6IJQXg5svhA9QeRv56XAmESIGVv+68rKKaqxDroWIAU3bTiGEaGYSfDSX7BMVsyIcCD72nMrmknfWU2asyGHwcjPQPzKAeyd3Vzus/8o3DwO0F+bgo6OpFHnXyWphtuN/QWEWeAY03Xubk03D+6mei8AuKvjIrCX42PoRpO8Fzw4w/rGma58QQrQQEnw0F+tcgLy0Or2kuKyc+d/uoMyoMTS2AzMHR9E/KoAuIT4Y9KZaEDkptgFH5dkXbZ0l58PU89ExDoJ7wOkDaoE283BIUzB/7+EDTG2Ih6S/as77yDsNK59V2xMeB6+OTdc+IYRoIWRgublYz4KoY8/H68sPcygtj0BvN967ajCXDY2ie5hvReABcHipeg7pDTq9CmxyUhqx4S1YaSHknFTb5uADoNsU9dzUU27NgZ552MTchpqCjxVPQVE2hPeHQXOatHlCCNFSSPDRXKxvSHUIPv5OOsv7q1XA8tylfdV0WnvMN9je/1B/8UP76f0w59B4BNj2IHSbqp4PL1W5Nk3BWA6pu9V2eH/1XFvwcXIbbP9cbZ//MugNTdM2IYRoYWTYpbnYVOHMhZL8ahcPKywp575vd2LU4JKBndSMFntKi+DISrXdbYq6GafvU8MB3ac2bvtbIutkU+uS5JHDVEBSeBa+vw48/CqORZ0DA2dXf819v6jeo6E31FzmPOMQlBaAq3dF0GEJPhJVnRHr1xuNsOg+td3/SogaVuePKYQQrZ0EH82l8l/DuakqR8COF5cc4EhGPqF+7jx5Ye/qr3lsnboB+oZDWD+Ve7Dz64rCV21d5ZkuZgYX1fux6xvY97Ptsb8/U9979DlVr5e6B76boxaI8w6C3pdU/97m3qWwvhU9GB3jAB0U50D+afAJqTj/+HpI/lvNjJn4pAMfUgghWj8JPppDaVFF9VEPfzXmX03wselIJgvXHwPghRn98Pdyrf665lku3aaov7LNuQftZdilcrKptcnPQGhvNRXW7PhfahruovvgptW2wx6apqa/akb185JH1MyZ6pa2Nwd41tNkXdwhIAqyklTbrIMP8++q53TwDXXkUwohRKsnOR/N4exRQFOBR0gvtS/Pft7HpxuOAXDZkEjGdQ+xew6gbpbmfA9zjkNoH0AHucmQl94oTW/RrAuMVeYTAqPuhLH3Vzwu/VD9DlJ3w7aFtufv/l7NVHHxBL9IyDkFa1+p/r0t02wH2O6vLu/D8ruaUqePJoQQbYkEH83BenjA15S/kVt1uq2maWw+ehaAfw6Oqvma6fshOwlcPCDuXLXP3QeCuqnt9tD7Ud2wS3W8g+C8R9X2imfUejgAxbmwzFRvY+y9MO0Ftf3Xm/bXajEaIXWX2jYnm5rZCz4yEyHzMOhdVAl4IYRoZxwOPk6dOsVVV11FYGAgnp6e9O3bl61bt1qOz507F51OZ/OYOrUdJDs6wvom6WMOPqpOhz2WWUBGXjFuBj39ImtZZMzcjR83Fty8Kvabb4ZtPe+j4AwUmIKHjp3r/roh16keoqIs+PNptW/NS+r30SEORtwBPS6A+AmqKNzih6teIzNBrcni4lkR7JnZCz7M06FjRsricUKIdsmh4OPs2bOMGjUKV1dX/vjjD/bt28crr7xChw4dbM6bOnUqKSkplsfXX3/dqI1u9ez1fNgpNLbl2BkA+kX64+FayzTM6rrxLXkfO+rX1tbCPM3WN0L1+NSVwQXOf0ltb/sUdn0HG95RP097AVw9VP7MtBdA7wqHl8DBSuvEWJJN+6jrWTMPAVn3mFhycyQoF0K0Tw4lnL7wwgtERUWxcGHF+HhcXFyV89zd3QkLq2Y6qLBdebW8VG3bqfWx5agKPobG1VL1suAMnNystrtWCj7MOQhtfdilpnyP2sSMhL6Xwe5v4ccb1L6uU2wDuaCuMGIerH8dFj8IncepwASqVja1Zu75OHNE1QIpyVeLyJnfQwgh2iGHej5++eUXhgwZwsyZMwkJCWHgwIF8+OGHVc5btWoVISEhdO/enVtvvZXMzMxqr1lcXExOTo7No82zXn/ExzTTwV7wYer5GBZbS/BxaLGalRHaR82usBbWVz1nn6jIaahO9kn4YBysfK76cwqz4JPp9ocfnCHvNHxwHqx+yXa/o/kelU16GtxMPSYGN5i6oOo5Y+9X05jPHoOXusALseqx6X113N6CcP5R6nrlxer7PbISjKXqdx9Uz7YKIUQr51DwceTIEd599126du3KkiVLuPXWW7nzzjv59NNPLedMnTqVzz77jBUrVvDCCy+wevVqpk2bRnm5/cqSCxYswN/f3/KIiqolsbK1K8xSNR9A/ZXuG662K812Sc8t4lhmATodDIqxHdayUVoEq00Jkb0urnrcw6/ihlzb0MvihyF5u7reyW32z1n1PBxbCxvfVYGAs+3+VtXHWPksnLJqY0ODD7/winob5z5gvwfF3aci+bQkVxUtKzyrggkXD5VvU5neUJGDkplQdUaSEEK0Qw4NuxiNRoYMGcJzz6m/jAcOHMiePXt47733mDNHrUsxa9Ysy/l9+/alX79+xMfHs2rVKiZMmFDlmg8//DDz58+3/JyTk9O2A5AzpiEXnzBw962o8VCUrdYmcfUEYOsxNcule6gv/p411Pb46031l7hvOJxzm/1zwvurG1/KDuhS9XcAqHoX+3+p+HnRvXDDn2p1VrO0vbD5A9MPGiQsgwFX1vhxG51lxV5THY7rl6s2NjT4ABh2oyok5h1U/Tm9Lob5+9WMGGvewdUvChfYRS1sl3FYptgKIQQO9nyEh4fTq1cvm309e/YkKSmp2td07tyZoKAgEhLsr2/h7u6On5+fzaNNq1wIyyMADKZ1WqySTjeb8j2G1ZTvkZVUUXti8r+rT7SsLe+jrAT+eFBt971MVd1M3l6x7giYim49AFq5mtUBVoGAkxRlq8JgoNpwahvs+FK1LdOUcNqQ4ANqDjzM/CIguLvto6bVaM29KLu/hYIMcPeD6BENa6cQQrRiDgUfo0aN4uDBgzb7Dh06RExMTLWvOXnyJJmZmYSHh9evhW1N5cRInc6q1kfF0MvW46Zk05ryPZY8AmWFEDO65qXizbkI1U233fSeWpvEO1jN/DjPlM+x4ik1rACw5wc4vk7d9C95V+1L+FMFLs6S+CcYy9R01vGPqH3Ln1S9CqX5oDNAh+r/W2w25oDIPEwUPx5c3JqvPUII0cwcCj7uueceNm7cyHPPPUdCQgJfffUVH3zwAfPmzQMgLy+P+++/n40bN3Ls2DFWrFjBxRdfTJcuXZgyRbqZAfvDA5WCj9yiUvYlq8TbaoOPxJVqmERnUHkINS16FtZPPWcdVzNjrOWkVOSMTHwSPANg2E1qRdyCTJV8WpwHS03FuMbcCz0vVoFKSa6qAuos1kMWw2+BoO6qJ+GnW9T+DrFgqGGIqrlU7o2RfA8hRDvnUPAxdOhQfvrpJ77++mv69OnDM888w+uvv87s2WpVUIPBwK5du7jooovo1q0b119/PYMHD2bt2rW4u1ezBHx7Yy/4MM94MQ27/J2UhVGDqI6ehPl7VL1GWQn88YDaHnajqi9RE88AVTALKipxmi17XBXI6jREra4K6gY+7UW1veW/8NPNpqJbsTDyDpVjYZ4memhprR+5URjLK4pzdZtqaqMpaDIn0jZ0yKWp2LRLB10nNVtThBCiJXB4Ybnp06czffp0u8c8PT1ZsmRJgxvVZmma/cXPLD0fqsqppb5Hdb0em99XwyReQTCujlNew/urNWUO/K6KZYHKGdn9LaBTwy3WyaWdz1XJl3t/ggO/qX1Tn6+obdFtCuz4QuV9TK1ham5NCrNUEqs1vYsaJnKpFKye2qZ6Yjz8IWq42hd/nkoA3fc/9XN9anw4g3ewyqMpyYXIoXXLKxFCiDZMVrV1prw01cug06teBLNK67vUWN+jrARWm3olJj2lejXqImKAWk5+8wdWM1ZMBs+BToOqvmbyv9VQR2mBWtHVergg/jwVxJxJhIyE+tWs+GgyZBysur/nRXD557b7zMmtXSbaDq1Mflb1vpQVttzgQ6dTbUvZAd0mN3drhBCi2cnCcs5kHnIJiLFNODSv75KXSnFZOTtOZAEwxF7wkZsCxTlqhkx/B6a59p2pZlgEdbN9dB4HE56w/xr/SJj+ulqo7vyXbfNK3H0hdrTars+sl4IzFYGHdXt0BpXLcni57fnV1ccIiIKL34LO50GvSxxvh7OMuVe1ffC1zd0SIYRodtLz4UzV1aLwrahyuudUNsVlRgK93YgP9q56DfOMGN9Q22GS2vhHwnX1CBL6X64e9nSbqip2HloMI2937LrWa7HcvqVi/+J/wca3VQnzuA0qSMs6AWl7VI9Rl4lVr9X3n+rRkvW6SD2EEEJIz4dTVQo+zuSXsGJ/GvluwWp/bipbTMXFhsR2QGdvBou5Eqq5t6Q5mYcQkjao/A1HVLcWy7gHwTtEHd9oWuDtsKnXI3JYzfU0hBBCtAoSfDiT9YJywBO/7OX6T7cy+b+m4YfCM2w/ooKLapNNTXkhlt6S5tSxs5ruaixTNTgcUV3w4eGv1lkBlduSkyxVQYUQoo2R4MOZKvV8mGe1nCrxokQzALD30GGghuDD3PPh20KKtpkDgkMOznKqqRx6v8vVjJbSfFVC/ega03tJfQwhhGgLJPhwlvIyOHNUbQd24Wx+Cak5RQB8eM1Qcl0DAQgmC193F3pHVFNm3pzz4dMCej6gIiBIWKZqcdRVTcGHXm+qM6JT03zLisA/GkJ6Nri5Qgghmp8knDpLdlLF6qd+ndhv6vWI6ujJpF6hsD4aTqVz0yAvfAYMwsVQTVxoSThtATkfoHooPPxVDY7/3a62zWJG2k+yrMtaLBEDYMi1sPVj9XO3KTVXcRVCCNFqSPDhLCmmyqKBXUCvZ3+KWhW1Z5iph8MUTEyL0UHX4OqvY158rqUEHwYXVe1097ew8yvbY1s+hAeO2AYkoAIo81osATWsxTL+MVXkrPAsdJ/W+G0XQgjRLCT4cJbDy9Rz3LkA7E9Ra7f0DLcNPqwXl7PLVAW1Rcx2MZv0tAqqyosr9m37RPWGpOyCuDG255uHXDrE1LzAmldHuOYXVQU1fnyjN1sIIUTzkODDGYzGiumipumpVYIPq0Jj1SorUTd0aDk9HwB+4WqKrLXTB1W+RsrO6oOPuqzFEt5PPYQQQrQZknDqDMnbIf+0Wt8jeiRl5UYOp+UB0DPcV51jKTSWVv118tPVs94VPFt4vYvwAerZvOibNUeCDyGEEG2OBB/OYFmXZDy4uHEkI5+SciPebgaiOnipY+apszUNu1jPdHGkumlziBignpN3VD1Wqd6JEEKI9qWF38HaCHPwYZqWah5y6RHuh15vmsFhnjpb07CLdWn1li68v3rOTIDiXNtj0vMhhBDtmgQfTS0nGVJ3ATroMgmAfZZ8D9+K88w5HPkZUF5q/1otqbR6bXxC1LotaJC6u2J/eRmcrah3IoQQov2R4KOpHV6qniOHgI+aQnvANM22R5hVITGvIDX1FA3y0u1fq6XV+KiNeeglZWfFvqzjqhy7i6cpOBFCCNHeSPDR1OysS1JlpguoHI7ahl5aW/BhTjq1zvuwzvdo6XkrQgghmoT869+USgvhyCq1bcr3yMwrJj1X1cPoEeZre35tM17MBcZaSmn12pjzPqxnvFS3oJwQQoh2Q4KPpnRsHZQWgF8nCO0DwIFUNeQSE+iFt3ulMivmXA5zIbHKzPtbyqJytTEPu2QcgpJ8tS3JpkII0e5J8NGUzLNcuk62rEtiGXIJs7NwnHk4Ja+ang9zj0hrmO0C6vP4hIFmhNQ9ap8EH0II0e5J8NFUNM0q36NiKfh99vI9zGoqsV5epgqVQeuY7WJmGXoxJZ2eqWVBOSGEEG2eBB9NJX0fZJ9Qq9jGjbXstiwoF+5b9TXmXA57wUf+aUBTM2K8g5qgwU3EMuNlh8qByT6hfu4oOR9CCNFeSfDRVMy9HnHngpuqYlpabiQh3Rx82Ov5MOVy2JvtYllQLgT0hsZubdMx93wk76jo9fAIUIvGCSGEaJck+GgqCcvVs9UU28TTeZSWa/i6uxDZwbPqa8y5HDl2Ek5b20wXM/N029MHKvI+ArtYcmCEEEK0PxJ8NJWMQ+q502DLroqy6r7o7N18zUMR+emQn2l7rLXV+DDziwDvYNDKYd//1D7J9xBCiHZNgo+mUFpYkRwaEG3ZXZHvYWfIBcDDryIASdlue6y1Bh86XcXQS8Iy9SzBhxBCtGsSfDSFnGT17OoNnh0suy09H/am2ZrZK0kOrWtdl8rMQy/lJepZCowJIUS7JsFHU8hKUs/+kTa5DTXOdDGzTtC01tpqfFgzB1Rm0vMhhBDtmgQfTSH7pHoOiLLsOp1bTEZeMToddK9cVt2auZegcs9Ha6tuas0cUJl17Nw87RBCCNEiSPDRFMzBh3+kZZd5yCU20BsvNxd7r1LMN+qs41BwpmJ/a53tAuAfBZ6mqbW+EeDu07ztEUII0awk+Kgs8c+KabL1ZS6kZRV87EnOBqB3RA35HgCeAdAhVm2n7lLPxnLIS1fbrS3hFGyTTiXfQwgh2j0JPqyVFsHXV8AX/4ST2+p/HUvwUTHTZc8pFXz07eRf++srL0Wfn6GmqqID75D6t6s5RQ1Tz6G9m7cdQgghmp0EH9aKsqGsCNBg0X1gNNbvOll2ej5OqWGXPnUKPiqth2Ke6eIdDIYahmxaspF3wuRnYez9zd0SIYQQzUyCD2sleRXbyX/Dji8cv4bRCDmn1LYp4TS7oJSkMwUA9ImoQ/BhvR4KtO6ZLmbuPjDy9ta1Lo0QQogmIcGHNevgA2D5k1B41rFr5J9W9Sx0esvMFHO+R1RHT/y9XGu/hnnY5cwR1RtjWdelFeZ7CCGEEJVI8GGt2BR8BMRAcA8oyISVzzl2DXO+h284GFSg4VC+B6hF18z5Iim7Kma6tMZkUyGEEKISCT6smXs+PDvAtBfU9pb/ViyIVheWZNOKGh+7TcFHnfI9zCLMeR87Wm9pdSGEEMIOCT6smYMPNx/oPA56/QM0Iyy6HzStbtewk2y6N9mUbFqXfA8z66TT1lzjQwghhKhEgg9r5mEXcxGsyf8GVy9I+gv2/FC3a1QqMJZTVMrRjHzAwZ6P8IHqOXlH665uKoQQQlQiwYc1654PULNVRt6ptrd/XrdrVCqtvs/U69EpwJOO3m51b4u55yMzQSWeggy7CCGEaBMk+LBWonoocPOu2Nd3pno+th6Kcmq/RrZ5UTkVfOyx5HvUUtm0Mp9g8OsEaBUzbmTYRQghRBvgcPBx6tQprrrqKgIDA/H09KRv375s3brVclzTNB5//HHCw8Px9PRk4sSJHD58uFEb3WSK1aqzuFst/BbUBTrGg7EUjqys/RqWYRcVfOx2dKaLNfOUWzMJPoQQQrQBDgUfZ8+eZdSoUbi6uvLHH3+wb98+XnnlFTp06GA558UXX+SNN97gvffeY9OmTXh7ezNlyhSKiooavfGNztLzUWnhs25T1fOhJTW/vjivopfClPNh7vnoXa/gw2o1WK9AcHFg2EYIIYRooRyq1f3CCy8QFRXFwoULLfvi4uIs25qm8frrr/Poo49y8cUXA/DZZ58RGhrKzz//zKxZsxqp2U3EkvPhbbu/2xTY+LYKPoxG0FcTs5l7Pdz9wcOPvOIyjpiTTR2Z6WJmrnQKUmBMCCFEm+FQz8cvv/zCkCFDmDlzJiEhIQwcOJAPP/zQcvzo0aOkpqYyceJEyz5/f3+GDx/Ohg0b7F6zuLiYnJwcm0ezqTzbxSx6BLj7QUGGKrtenUrJpvtTctA0CPPzINjX3fH2WA+7tObS6kIIIYQVh4KPI0eO8O6779K1a1eWLFnCrbfeyp133smnn34KQGqqKoYVGmp7owwNDbUcq2zBggX4+/tbHlFRUXbPcwpLz4ev7X4XN4gfr7YPLa7+9ZZkUzXksvtkPYqLWfMNrejxkGm2Qggh2giHgg+j0cigQYN47rnnGDhwIDfddBM33ngj7733Xr0b8PDDD5OdnW15nDhxot7XarDqhl3AKu+jpuDDtsaHw2XV7TEPvUiyqRBCiDbCoeAjPDycXr162ezr2bMnSUnqL/6wMPVXelpams05aWlplmOVubu74+fnZ/NoNtUNuwB0nQToIHU35CTbf32lmS7mBeUcnmZrbfC1ENILel5Y/2sIIYQQLYhDwceoUaM4ePCgzb5Dhw4RExMDqOTTsLAwVqxYYTmek5PDpk2bGDFiRCM0t4lVN9sF1FLwkUPVdnWzXqxKqxeUlJGQroKZBvV8dJ8Kt22AToPqfw0hhBCiBXEo+LjnnnvYuHEjzz33HAkJCXz11Vd88MEHzJs3DwCdTsfdd9/Nv//9b3755Rd2797NNddcQ0REBP/4xz+aov2Nq8RU58Ne8AFq1gtUH3xYEk6j2Z+Si1GDYF93Qvw8GredQgghRCvmUPAxdOhQfvrpJ77++mv69OnDM888w+uvv87s2bMt5zzwwAPccccd3HTTTQwdOpS8vDwWL16Mh0cLvwFrWs3DLlCR93FkFZQW2h4rL4OcU2rbP7Jx8j2EEEKINsihOh8A06dPZ/r06dUe1+l0PP300zz99NMNapjTlRWDVq62q+v5CO0NfpGQcxKOroVukyuO5aWq1+tdwCeUPaf2AA2Y6SKEEEK0UbK2i5l5pgvYn+0CoNNZDb1UmvViHnLx6wR6A/tSVL2S3hHNmEArhBBCtEASfJiZ13Vx9QK9ofrzrEuta1rFfkuyqZrpcvKsGpaJDawmkBFCCCHaKQk+zOytaGtP3Bhw8VRDL4eXVuzPNgUfAVEUlJSRXVgKQHhAC891EUIIIZxMgg8zS4GxavI9zFw9YdgNanvxQypXBGwKjKVkq0X0fNxd8PNwbYLGCiGEEK2XBB9mtc10sTb2AVX2/MwR2PCW2pddUeMjJUsFH+H+0ushhBBCVCbBh1ldez4APPxgkmk2z5qXVa+HVXXT5GyV7xEe4NkEDRVCCCFaNwk+zBwJPgD6XaZWuy0tgKWP2iScmns+IqTnQwghhKhCgg8zR4ZdQE27nfYi6PSw96eK6qj+nUgx93z4S8+HEEIIUZkEH2Y1rWhbnfB+MOT6ip+9AsHNm2RTwqnMdBFCCCGqkuDDzBJ8+Dr2uvP+pYIOAP9IAFKyVM9HhPR8CCGEEFVI8GHm6LCLmVdHmPSM2u40BMAy1VZ6PoQQQoiqHF7bpc2qa5ExewbOhsihEBBFTlEpecVlgPR8CCGEEPZI8GFmThit62yXyoK7AZCSqa4T4OWKp1sNZdqFEEKIdkqGXcwswy4O5nxUYq7xEeYnQy5CCCGEPRJ8mDVk2MWKpcaHFBgTQggh7JLgw8zRImPVqKjxIT0fQgghhD0SfJiVNM6wi3mmi/R8CCGEEPZJ8GFWXI8iY3ZIz4cQQghRMwk+zBpr2MWyoq30fAghhBD2SPABUFYC5SVq29EiY1Y0TbPMdomQAmNCCCGEXRJ8QEWvBzSo5yOroJSiUiMAYTLsIoQQQtglwQdUBB8GdzC41vsy5l6PIB833F2kwJgQQghhjwQf0Og1PiTfQwghhKieBB9Q/0XlKpGZLkIIIUTtJPgAq3VdGlpaXWp8CCGEELWR4AMacdhFej6EEEKI2kjwAY027GLu+ZCZLkIIIUT1JPiARl/XRYZdhBBCiOpJ8AGNEnwYjRqp2ebZLtLzIYQQQlRHgg9olGGXzPwSSss1dDoI9ZPgQwghhKhOuw4+Ek/n8fCPu9iReBKAIn39h0vMQy4hvu64Gtr11yqEEELUqF3fJT9ed5SvN5/gYFIqAG+sTWHcSyt56te9ZBeUOnStZCkwJoQQQtRJuw4+MvPUYnIRnmUA5OPJscwCFq4/xoRXV/PbrmQ0TavTtVJkQTkhhBCiTtp18JFdqHo3unVQPz940WA+uHow8cHeZOQVc/tX27n+062cPFtQ67VSsqXnQwghhKgLCT4Ad00FDl4+/kzuHcaiu8Zw98SuuBn0/HkgncmvrWHt4dM1XitZCowJIYQQdSLBB+BWbqpwaprt4u5i4O6J3Vh012iGxHSgoKScl5YcrPFaKVJaXQghhKiTdh185JiCD9cy07BKpbVduoT48v7Vg3E16Nh1Mps9p7KrvZaUVhdCCCHqpt0GH+VGjdxilWhqKKt+bZdAH3cm9w4D4JstSdVeKy23GJCeDyGEEKI27Tb4MPd6AOhKbIddKrtiaDQA/9ueTEFJWZXj6blFlBs1XPQ6gnzcG7+xQgghRBvSfoOPIhV8+LqBrkwNmVRXXn1kfCDRHb3ILS7j910pVY6ba3yE+nlg0OuapsFCCCFEG9Fugw9zsmmoR3nFzmqCD71ex+VDowD4ZsuJKscPpOYAku8hhBBC1EW7Dz7CPEzDKHoXcKl+yGTm4EgMeh3bjp/lUFquZX/i6TwWLDoAwOiuQU3XYCGEEKKNcCj4ePLJJ9HpdDaPHj16WI6PGzeuyvFbbrml0RvdGMzBR7CbKffDzRt01Q+ZhPh5MKFHCABfb1aJp3nFZdz8+TbyissYFtuReed1adpGCyGEEG2Ai6Mv6N27N8uXL6+4gIvtJW688Uaefvppy89eXl4NaF7TMQcfgZbgw7eGs5UrhkezdF8aP20/xYNTe3DftztJSM8j1M+dt2YPlAXlhBBCiDpwOPhwcXEhLCys2uNeXl41Hm8pLMGHq1rfpbqZLtbGdg2mU4Anp7IKmfPxZjYdPYOrQcc7swcT4iv5HkIIIURdOPyn+uHDh4mIiKBz587Mnj2bpCTb2hdffvklQUFB9OnTh4cffpiCgprXRSkuLiYnJ8fm4Qzm4KODi9WwSy0Meh0zh0QCsOnoGQCevKg3g2M6NE0jhRBCiDbIoeBj+PDhfPLJJyxevJh3332Xo0ePMmbMGHJzVQLmlVdeyRdffMHKlSt5+OGH+fzzz7nqqqtqvOaCBQvw9/e3PKKiour/aRyQU6gSTQMMqjhYdTNdKrtsSBTm2bSXDYnkymHRTdE8IYQQos3SaXVdM96OrKwsYmJiePXVV7n++uurHP/zzz+ZMGECCQkJxMfH271GcXExxcXFlp9zcnKIiooiOzsbPz+/+jatVvO+/Jvfd6fw9YC9jDjwLPSYDrO+rNNrP153lMTTeTw2vRceroYma6MQQgjRWuTk5ODv71+n+7fDOR/WAgIC6NatGwkJCXaPDx8+HKDG4MPd3R13d+dXBTUPu/hYej5qH3Yxu250XFM0SQghhGgXGjQ9Iy8vj8TERMLDw+0e37FjB0C1x5uTJfig5uqmQgghhGhcDvV83HfffVx44YXExMSQnJzME088gcFg4IorriAxMZGvvvqK888/n8DAQHbt2sU999zD2LFj6devX1O1v97MwYcXqjR6XWa7CCGEEKLhHAo+Tp48yRVXXEFmZibBwcGMHj2ajRs3EhwcTFFREcuXL+f1118nPz+fqKgoZsyYwaOPPtpUbW8Qc/DhYZSeDyGEEMKZHAo+vvnmm2qPRUVFsXr16gY3yBmMRs2ysJy70TQVWIIPIYQQwinaZUnOvJIyzHN8XMtNwYcMuwghhBBO0S6Dj+wCU6+Hix5Dqbnno+6zXYQQQghRf+0z+DDle/h7ukKJaYXaOqztIoQQQoiGa5fBR4518FGcp3bKsIsQQgjhFO0y+LDt+chXO2XYRQghhHCKdh18+Hm6Qomp50NmuwghhBBO0a6DjwAPgwQfQgghhJO1y+DDXOMjyL28YqfkfAghhBBO0S6DD3PPR6BbqWmPDly9mq9BQgghRDvSToOPMgA6upSoHW4+oNM1Y4uEEEKI9qOdBh+qx6ODOfiQIRchhBDCadp18BFgKFY7JNlUCCGEcJp2GXyYi4z56s0r2kqNDyGEEMJZ2mXwYe758NGbej7cpbS6EEII4SztLvjQNM3S8+FNkdopwy5CCCGE07S74KOgpJwyowaAlybDLkIIIYSztbvgwzzk4mrQ4VpeoHbKbBchhBDCadpt8OHv6YpOSqsLIYQQTtdugw8/T1fIOKx2uvs1Y4uEEEKI9qXdBh+jDXvh0GLQ6aHHBc3cKiGEEKL9aJfBhwtl3Jz/vtox5HoI69O8jRJCCCHakXYXfOQUljLHsJROpcfBKxDO+1dzN0kIIYRoV9pd8FGWncLdLj+oHyY8AV4dm7dBQgghRDvT7oKPc468ga+ukBTvXjDw6uZujhBCCNHutK/gI2kTA84sBmBTz4dB374+vhBCCNESuDR3A5zGWA6L7gPg/8rGoQsd2MwNEkIIIdqn9vOn/4HfIXUX+TpvXiy7XNX5EEIIIYTTtZ/go+eF8M+FvOl+A5n44+fZfjp9hBBCiJak/QQfOh30uZTvy8YCqry6EEIIIZyv/QQfJjlFFWu7CCGEEML52lXwUVRaTkmZEZDgQwghhGgu7Sr4MK/rYtDr8HGXnA8hhBCiObTL4MPPwwWdTtfMrRFCCCHap3YZfMiQixBCCNF82lfwUSDBhxBCCNHc2lfwYR52keBDCCGEaDbtKvgwT7OV4EMIIYRoPu0q+JCcDyGEEKL5SfAhhBBCCKeS4EMIIYQQTtWugo8cCT6EEEKIZteugg/p+RBCCCGan0PBx5NPPolOp7N59OjRw3K8qKiIefPmERgYiI+PDzNmzCAtLa3RG11fFRVOJfgQQgghmovDPR+9e/cmJSXF8li3bp3l2D333MOvv/7Kd999x+rVq0lOTubSSy9t1AY3RE5hGSA9H0IIIURzcnh1NRcXF8LCwqrsz87O5qOPPuKrr75i/PjxACxcuJCePXuyceNGzjnnnIa3toFk2EUIIYRofg73fBw+fJiIiAg6d+7M7NmzSUpKAmDbtm2UlpYyceJEy7k9evQgOjqaDRs2VHu94uJicnJybB5NoaTMSGFpOSDBhxBCCNGcHAo+hg8fzieffMLixYt59913OXr0KGPGjCE3N5fU1FTc3NwICAiweU1oaCipqanVXnPBggX4+/tbHlFRUfX6ILUx93rodODr4XCHjxBCCCEaiUN34WnTplm2+/Xrx/Dhw4mJieHbb7/F09OzXg14+OGHmT9/vuXnnJycJglAzMGHr7sLer2u0a8vhBBCiLppUBdAQEAA3bp1IyEhgUmTJlFSUkJWVpZN70daWprdHBEzd3d33N3dG9KMOvHzdOHuiV3RIYGHEEII0ZwaVOcjLy+PxMREwsPDGTx4MK6urqxYscJy/ODBgyQlJTFixIgGN7ShQnw9uHtiN+6a2LW5myKEEEK0aw71fNx3331ceOGFxMTEkJyczBNPPIHBYOCKK67A39+f66+/nvnz59OxY0f8/Py44447GDFiRIuY6SKEEEKIlsGh4OPkyZNcccUVZGZmEhwczOjRo9m4cSPBwcEAvPbaa+j1embMmEFxcTFTpkzhnXfeaZKGCyGEEKJ10mmapjV3I6zl5OTg7+9PdnY2fn5+zd0cIYQQQtSBI/fvdrW2ixBCCCGanwQfQgghhHAqCT6EEEII4VQSfAghhBDCqST4EEIIIYRTSfAhhBBCCKeS4EMIIYQQTiXBhxBCCCGcSoIPIYQQQjiVBB9CCCGEcCqH1nZxBnO195ycnGZuiRBCCCHqynzfrsuqLS0u+MjNzQUgKiqqmVsihBBCCEfl5ubi7+9f4zktbmE5o9FIcnIyvr6+6HS6Rr12Tk4OUVFRnDhxQhata2LyXTuPfNfOI9+188h37TyN9V1rmkZubi4RERHo9TVndbS4ng+9Xk9kZGSTvoefn5/8x+wk8l07j3zXziPftfPId+08jfFd19bjYSYJp0IIIYRwKgk+hBBCCOFU7Sr4cHd354knnsDd3b25m9LmyXftPPJdO498184j37XzNMd33eISToUQQgjRtrWrng8hhBBCND8JPoQQQgjhVBJ8CCGEEMKpJPgQQgghhFNJ8CGEEEIIp2o3wcfbb79NbGwsHh4eDB8+nM2bNzd3k1q9BQsWMHToUHx9fQkJCeEf//gHBw8etDmnqKiIefPmERgYiI+PDzNmzCAtLa2ZWtx2PP/88+h0Ou6++27LPvmuG8+pU6e46qqrCAwMxNPTk759+7J161bLcU3TePzxxwkPD8fT05OJEydy+PDhZmxx61ReXs5jjz1GXFwcnp6exMfH88wzz9gsTCbfdf2tWbOGCy+8kIiICHQ6HT///LPN8bp8t2fOnGH27Nn4+fkREBDA9ddfT15eXsMbp7UD33zzjebm5qZ9/PHH2t69e7Ubb7xRCwgI0NLS0pq7aa3alClTtIULF2p79uzRduzYoZ1//vladHS0lpeXZznnlltu0aKiorQVK1ZoW7du1c455xxt5MiRzdjq1m/z5s1abGys1q9fP+2uu+6y7JfvunGcOXNGi4mJ0ebOnatt2rRJO3LkiLZkyRItISHBcs7zzz+v+fv7az///LO2c+dO7aKLLtLi4uK0wsLCZmx56/Pss89qgYGB2m+//aYdPXpU++677zQfHx/tP//5j+Uc+a7rb9GiRdojjzyi/fjjjxqg/fTTTzbH6/LdTp06Vevfv7+2ceNGbe3atVqXLl20K664osFtaxfBx7Bhw7R58+ZZfi4vL9ciIiK0BQsWNGOr2p709HQN0FavXq1pmqZlZWVprq6u2nfffWc5Z//+/Rqgbdiwobma2arl5uZqXbt21ZYtW6ade+65luBDvuvG8+CDD2qjR4+u9rjRaNTCwsK0l156ybIvKytLc3d3177++mtnNLHNuOCCC7TrrrvOZt+ll16qzZ49W9M0+a4bU+Xgoy7f7b59+zRA27Jli+WcP/74Q9PpdNqpU6ca1J42P+xSUlLCtm3bmDhxomWfXq9n4sSJbNiwoRlb1vZkZ2cD0LFjRwC2bdtGaWmpzXffo0cPoqOj5buvp3nz5nHBBRfYfKcg33Vj+uWXXxgyZAgzZ84kJCSEgQMH8uGHH1qOHz16lNTUVJvv2t/fn+HDh8t37aCRI0eyYsUKDh06BMDOnTtZt24d06ZNA+S7bkp1+W43bNhAQEAAQ4YMsZwzceJE9Ho9mzZtatD7t7hVbRtbRkYG5eXlhIaG2uwPDQ3lwIEDzdSqtsdoNHL33XczatQo+vTpA0Bqaipubm4EBATYnBsaGkpqamoztLJ1++abb/j777/ZsmVLlWPyXTeeI0eO8O677zJ//nz+9a9/sWXLFu68807c3NyYM2eO5fu092+KfNeOeeihh8jJyaFHjx4YDAbKy8t59tlnmT17NoB8102oLt9tamoqISEhNsddXFzo2LFjg7//Nh98COeYN28ee/bsYd26dc3dlDbpxIkT3HXXXSxbtgwPD4/mbk6bZjQaGTJkCM899xwAAwcOZM+ePbz33nvMmTOnmVvXtnz77bd8+eWXfPXVV/Tu3ZsdO3Zw9913ExERId91G9fmh12CgoIwGAxVsv7T0tIICwtrpla1Lbfffju//fYbK1euJDIy0rI/LCyMkpISsrKybM6X795x27ZtIz09nUGDBuHi4oKLiwurV6/mjTfewMXFhdDQUPmuG0l4eDi9evWy2dezZ0+SkpIALN+n/JvScPfffz8PPfQQs2bNom/fvlx99dXcc889LFiwAJDvuinV5bsNCwsjPT3d5nhZWRlnzpxp8Pff5oMPNzc3Bg8ezIoVKyz7jEYjK1asYMSIEc3YstZP0zRuv/12fvrpJ/7880/i4uJsjg8ePBhXV1eb7/7gwYMkJSXJd++gCRMmsHv3bnbs2GF5DBkyhNmzZ1u25btuHKNGjaoyZfzQoUPExMQAEBcXR1hYmM13nZOTw6ZNm+S7dlBBQQF6ve1tyGAwYDQaAfmum1JdvtsRI0aQlZXFtm3bLOf8+eefGI1Ghg8f3rAGNChdtZX45ptvNHd3d+2TTz7R9u3bp910001aQECAlpqa2txNa9VuvfVWzd/fX1u1apWWkpJieRQUFFjOueWWW7To6Gjtzz//1LZu3aqNGDFCGzFiRDO2uu2wnu2iafJdN5bNmzdrLi4u2rPPPqsdPnxY+/LLLzUvLy/tiy++sJzz/PPPawEBAdr//vc/bdeuXdrFF18s0z/rYc6cOVqnTp0sU21//PFHLSgoSHvggQcs58h3XX+5ubna9u3bte3bt2uA9uqrr2rbt2/Xjh8/rmla3b7bqVOnagMHDtQ2bdqkrVu3TuvatatMtXXEm2++qUVHR2tubm7asGHDtI0bNzZ3k1o9wO5j4cKFlnMKCwu12267TevQoYPm5eWlXXLJJVpKSkrzNboNqRx8yHfdeH799VetT58+mru7u9ajRw/tgw8+sDluNBq1xx57TAsNDdXc3d21CRMmaAcPHmym1rZeOTk52l133aVFR0drHh4eWufOnbVHHnlEKy4utpwj33X9rVy50u6/0XPmzNE0rW7fbWZmpnbFFVdoPj4+mp+fn3bttddqubm5DW6bTtOsSskJIYQQQjSxNp/zIYQQQoiWRYIPIYQQQjiVBB9CCCGEcCoJPoQQQgjhVBJ8CCGEEMKpJPgQQgghhFNJ8CGEEEIIp5LgQwghhBBOJcGHEEIIIZxKgg8hhBBCOJUEH0IIIYRwqv8HUYV5wr/PnykAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainloader = train_loaders[0]\n",
    "valloader = val_loaders[0]\n",
    "testloader = test_loaders[0]\n",
    "net = SimpleCNN(configuration['dropout']).to(device)\n",
    "losses = []\n",
    "accuracies = []\n",
    "for epoch in range(1):\n",
    "    train(net, trainloader, testloader, configuration, configuration['epochs'])\n",
    "    loss, accuracy = test(net, valloader, configuration)\n",
    "    losses.append(loss)\n",
    "    accuracies.append(int(accuracy))\n",
    "    print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
    "# plt.plot(accuracies)\n",
    "loss, accuracy = test(net, testloader, configuration=configuration)\n",
    "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('conv1.weight', tensor([[[-1.4129e-01, -7.0564e-02,  8.1542e-02,  4.6404e-02,  1.5343e-01],\n",
       "         [-1.8136e-02,  1.8754e-01,  1.0247e-01, -6.2279e-02,  1.2967e-01],\n",
       "         [ 9.6879e-02,  2.1495e-01,  2.1282e-01,  1.1060e-01,  1.0792e-01],\n",
       "         [ 2.4617e-01,  1.3293e-01,  1.8215e-01,  7.7971e-02, -2.5112e-02]],\n",
       "\n",
       "        [[-1.2716e-02, -5.4720e-02,  1.6456e-01,  8.2087e-02,  8.8038e-02],\n",
       "         [-1.4108e-01, -1.6467e-01, -1.9908e-01, -1.9334e-01, -1.5931e-01],\n",
       "         [ 1.5824e-01, -9.6195e-02,  1.8928e-01,  2.5056e-01,  2.3529e-01],\n",
       "         [-3.1609e-02,  1.8396e-01,  5.9121e-02,  5.6696e-02, -1.5406e-01]],\n",
       "\n",
       "        [[-1.4707e-01, -9.9898e-02,  2.2512e-01, -1.2680e-01,  1.4093e-01],\n",
       "         [-2.7668e-02, -1.3916e-01,  1.1802e-01,  1.7596e-02, -1.3424e-01],\n",
       "         [-5.8530e-02, -7.2586e-02, -1.7104e-01, -3.6989e-03,  1.8309e-01],\n",
       "         [ 2.1616e-01,  1.3113e-01,  2.4845e-01,  2.0815e-01, -7.9077e-02]],\n",
       "\n",
       "        [[ 6.0362e-02,  2.4419e-02,  1.1571e-01,  1.6471e-01, -1.1962e-01],\n",
       "         [ 2.2677e-01,  1.6415e-01,  1.3792e-01,  1.6328e-01,  4.3763e-02],\n",
       "         [-1.6780e-01,  1.1035e-01,  7.4938e-02, -1.2737e-01,  3.5664e-02],\n",
       "         [ 2.9933e-02,  2.4341e-01,  2.1257e-01,  1.9941e-01,  1.7237e-01]],\n",
       "\n",
       "        [[-1.9068e-01,  2.2802e-01, -1.8186e-02,  1.0282e-01,  2.4412e-02],\n",
       "         [-2.5236e-02,  8.8044e-02, -1.1743e-01, -1.8584e-01, -3.5603e-02],\n",
       "         [ 1.5501e-01, -4.6671e-02, -1.4063e-01,  2.1279e-01,  7.9590e-02],\n",
       "         [-2.2468e-01, -3.0078e-02,  9.1537e-02, -1.1613e-01, -8.7604e-02]],\n",
       "\n",
       "        [[-1.5477e-01,  3.9987e-02, -1.7231e-01,  4.6004e-02, -1.3465e-01],\n",
       "         [-1.7457e-01,  1.2554e-01,  1.7411e-01,  2.4168e-01, -1.8350e-01],\n",
       "         [-1.2786e-02,  1.2855e-01,  1.2666e-01,  1.8882e-01,  1.8903e-01],\n",
       "         [ 1.4269e-01,  2.0540e-01,  2.2259e-01,  1.9382e-01,  8.3793e-03]],\n",
       "\n",
       "        [[ 7.1315e-02, -9.2735e-02,  1.0942e-01,  2.0017e-01, -1.6268e-01],\n",
       "         [-6.8586e-03,  6.4516e-02, -1.3056e-01,  2.5403e-02, -1.3258e-01],\n",
       "         [ 1.4063e-01, -1.8641e-01,  2.1569e-01, -1.7203e-01,  1.0871e-01],\n",
       "         [-2.0469e-01, -6.3688e-02,  2.4392e-01, -1.0818e-02,  1.8653e-01]],\n",
       "\n",
       "        [[ 1.9912e-01,  1.0137e-01, -1.4144e-01,  1.5942e-01, -2.7157e-02],\n",
       "         [-1.7132e-01,  1.0171e-01,  1.6015e-04, -1.1055e-01,  2.5599e-02],\n",
       "         [-2.2020e-01, -2.1514e-01, -6.8398e-02, -6.8725e-05,  9.0123e-04],\n",
       "         [-8.4153e-02, -9.8740e-02, -2.1542e-01, -4.5747e-02, -1.9030e-01]]],\n",
       "       device='cuda:0')), ('conv1.bias', tensor([ 5.3216e-03,  1.6428e-03, -5.7945e-02,  2.2335e-02, -7.3639e-02,\n",
       "         2.6731e-05,  7.1521e-02, -8.3792e-04], device='cuda:0')), ('bn1.weight', tensor([1.0058, 1.0186, 1.0219, 1.0201, 0.9842, 0.9750, 0.9981, 0.9942],\n",
       "       device='cuda:0')), ('bn1.bias', tensor([-0.0044, -0.0341, -0.0247, -0.0452, -0.0559,  0.0064, -0.0015, -0.0651],\n",
       "       device='cuda:0')), ('bn1.running_mean', tensor([ 0.0194, -0.0005, -0.0534,  0.0282, -0.0772,  0.0215,  0.0703, -0.0182],\n",
       "       device='cuda:0')), ('bn1.running_var', tensor([0.0007, 0.0011, 0.0021, 0.0011, 0.0024, 0.0025, 0.0016, 0.0020],\n",
       "       device='cuda:0')), ('bn1.num_batches_tracked', tensor(1800, device='cuda:0')), ('conv2.weight', tensor([[[ 0.0652,  0.1541, -0.0642,  0.0268,  0.1735],\n",
       "         [ 0.1287, -0.1210,  0.0871,  0.0756,  0.0883],\n",
       "         [-0.1149, -0.0468,  0.0443,  0.0436, -0.0871],\n",
       "         [-0.0664,  0.1424,  0.0698,  0.0971,  0.1354],\n",
       "         [ 0.1277, -0.0710,  0.0472, -0.0952,  0.0651],\n",
       "         [ 0.0654,  0.0970, -0.0180,  0.1411,  0.1008],\n",
       "         [-0.1182, -0.1338, -0.1014, -0.1295, -0.0431],\n",
       "         [-0.0353, -0.0077,  0.0193,  0.0875,  0.1415]],\n",
       "\n",
       "        [[ 0.0329,  0.0709, -0.0612, -0.1019,  0.1114],\n",
       "         [ 0.0449,  0.1321,  0.0852, -0.0341, -0.1054],\n",
       "         [ 0.0654, -0.0496, -0.0260, -0.0138, -0.1110],\n",
       "         [ 0.0187, -0.0988,  0.0363,  0.1349, -0.0053],\n",
       "         [-0.1283,  0.1265,  0.0615,  0.1473, -0.0966],\n",
       "         [ 0.1573, -0.0103,  0.0278, -0.0023,  0.0839],\n",
       "         [-0.0448, -0.0483, -0.0497, -0.1253, -0.0546],\n",
       "         [-0.0843, -0.0595,  0.0783, -0.0545,  0.0930]],\n",
       "\n",
       "        [[-0.0364,  0.0603,  0.0924, -0.0269, -0.0721],\n",
       "         [-0.0819, -0.0337,  0.0658,  0.0891,  0.1044],\n",
       "         [ 0.1370, -0.0608, -0.0665, -0.1428,  0.0031],\n",
       "         [ 0.1635, -0.1311, -0.1146, -0.1053, -0.0282],\n",
       "         [ 0.1187, -0.0437,  0.0346,  0.1024, -0.0494],\n",
       "         [ 0.0152,  0.0816,  0.0739, -0.1242,  0.0850],\n",
       "         [ 0.1102,  0.0222,  0.1240,  0.0280,  0.0980],\n",
       "         [-0.0980,  0.0575, -0.1327, -0.0879,  0.0364]],\n",
       "\n",
       "        [[ 0.1346,  0.0811,  0.0759, -0.0836, -0.0426],\n",
       "         [ 0.1637,  0.0918,  0.0822, -0.0183, -0.0867],\n",
       "         [ 0.1309, -0.0174, -0.0869, -0.0377,  0.1242],\n",
       "         [ 0.1746, -0.1562, -0.1437,  0.0598, -0.0513],\n",
       "         [-0.1096, -0.0242,  0.0471, -0.0541,  0.0924],\n",
       "         [-0.0200,  0.0628, -0.1003, -0.1033, -0.0465],\n",
       "         [ 0.0620, -0.1479,  0.0953,  0.0096, -0.0062],\n",
       "         [ 0.0258, -0.0919, -0.0511, -0.0749, -0.0594]],\n",
       "\n",
       "        [[-0.0196,  0.0880, -0.1114,  0.1665, -0.0016],\n",
       "         [-0.0290,  0.1164, -0.0277, -0.0668, -0.0286],\n",
       "         [ 0.0737, -0.0222,  0.0987, -0.0827, -0.1095],\n",
       "         [ 0.0535,  0.0525,  0.1151, -0.0782, -0.0354],\n",
       "         [-0.1298, -0.1568, -0.0951, -0.0068, -0.0891],\n",
       "         [ 0.1454,  0.1362,  0.0639,  0.0890,  0.1093],\n",
       "         [ 0.0403, -0.0473, -0.1401,  0.0511,  0.0539],\n",
       "         [ 0.0372,  0.0662,  0.0013, -0.1081,  0.0986]],\n",
       "\n",
       "        [[ 0.0145, -0.1218, -0.0998,  0.1179, -0.0427],\n",
       "         [ 0.0590, -0.0797, -0.0044,  0.0681, -0.0031],\n",
       "         [ 0.0646,  0.0049, -0.1179, -0.1102, -0.0900],\n",
       "         [-0.1645,  0.0005, -0.0817, -0.0112, -0.1555],\n",
       "         [-0.0468, -0.0582, -0.0274, -0.0207, -0.0234],\n",
       "         [ 0.0465, -0.0978, -0.1317,  0.0617,  0.1004],\n",
       "         [-0.1348, -0.1026, -0.0769, -0.0703, -0.0410],\n",
       "         [ 0.0584, -0.1505, -0.0691, -0.0197, -0.1297]],\n",
       "\n",
       "        [[-0.1269,  0.1783, -0.0047,  0.1510, -0.0107],\n",
       "         [ 0.1367,  0.0840,  0.1037,  0.0516,  0.0472],\n",
       "         [ 0.1389, -0.0098, -0.1473,  0.0877,  0.1058],\n",
       "         [-0.0989, -0.1179, -0.0203,  0.1213, -0.1071],\n",
       "         [ 0.0961,  0.1314, -0.0661,  0.0778, -0.1159],\n",
       "         [-0.0420, -0.0682, -0.0075, -0.1636, -0.1371],\n",
       "         [-0.0189, -0.0612,  0.0801, -0.0239,  0.0826],\n",
       "         [-0.0048,  0.1193,  0.0580, -0.0767,  0.1441]],\n",
       "\n",
       "        [[ 0.0891, -0.0182,  0.0763,  0.1040, -0.1350],\n",
       "         [-0.0112, -0.0276, -0.1694,  0.0119,  0.0081],\n",
       "         [ 0.0069,  0.1687,  0.1333, -0.1389, -0.1302],\n",
       "         [-0.0312, -0.0125, -0.1010, -0.0837,  0.0127],\n",
       "         [ 0.1069,  0.0467, -0.0591,  0.1224,  0.0856],\n",
       "         [ 0.0471, -0.0672, -0.0164, -0.0501, -0.0522],\n",
       "         [ 0.0607,  0.0566, -0.0177,  0.0598,  0.0571],\n",
       "         [ 0.0286,  0.0057, -0.0085,  0.0394, -0.1328]]], device='cuda:0')), ('conv2.bias', tensor([ 1.2273e-03,  1.5275e-02, -1.2514e-02,  6.6707e-04, -4.7269e-03,\n",
       "         2.8785e-02,  9.7377e-05,  9.1609e-05], device='cuda:0')), ('bn2.weight', tensor([1.0558, 1.0633, 1.0600, 1.0851, 1.0497, 1.0538, 1.0605, 1.0698],\n",
       "       device='cuda:0')), ('bn2.bias', tensor([ 0.0127,  0.0002,  0.0057,  0.0036, -0.0053,  0.0418, -0.0144,  0.0047],\n",
       "       device='cuda:0')), ('bn2.running_mean', tensor([ 0.3148,  0.0599,  0.0712, -0.0012,  0.1009, -0.4747,  0.1984,  0.0157],\n",
       "       device='cuda:0')), ('bn2.running_var', tensor([0.0792, 0.0555, 0.0567, 0.0931, 0.0608, 0.1155, 0.1120, 0.0606],\n",
       "       device='cuda:0')), ('bn2.num_batches_tracked', tensor(1800, device='cuda:0')), ('fc1.weight', tensor([[ 0.0412, -0.0480,  0.0100,  ..., -0.0068,  0.0292, -0.0812],\n",
       "        [-0.0025, -0.0222, -0.0187,  ..., -0.0679,  0.0393, -0.0180],\n",
       "        [ 0.0337, -0.0314, -0.0159,  ...,  0.0706,  0.0130,  0.0166],\n",
       "        ...,\n",
       "        [ 0.0185, -0.0560, -0.0247,  ..., -0.0445, -0.0023,  0.0393],\n",
       "        [-0.0341, -0.0414, -0.0337,  ...,  0.0311,  0.0341, -0.0851],\n",
       "        [ 0.0393,  0.0481,  0.0593,  ..., -0.0037, -0.0671, -0.0082]],\n",
       "       device='cuda:0')), ('fc1.bias', tensor([ 0.0312, -0.0185,  0.0280,  0.0379,  0.0028, -0.0591,  0.0008, -0.0385,\n",
       "        -0.0202,  0.0577,  0.0354, -0.0198, -0.0389,  0.0175, -0.0036, -0.0225,\n",
       "        -0.0204, -0.0206, -0.0079,  0.0394, -0.0208,  0.0341, -0.0407,  0.0352,\n",
       "         0.0375,  0.0508,  0.0362,  0.0466,  0.0019, -0.0030,  0.0447,  0.0319,\n",
       "         0.0097,  0.0768, -0.0113,  0.0274,  0.0280,  0.0275,  0.0452, -0.0038,\n",
       "        -0.0294, -0.0310,  0.0481, -0.0524,  0.0317,  0.0301, -0.0161,  0.0088,\n",
       "        -0.0310, -0.0012,  0.0511, -0.0623,  0.0671, -0.0356,  0.0262, -0.0402,\n",
       "         0.0372,  0.0178,  0.0558,  0.0005, -0.0148,  0.0002, -0.0325, -0.0027,\n",
       "        -0.0390,  0.0457,  0.0671, -0.0552, -0.0645, -0.0175, -0.0492,  0.0723,\n",
       "        -0.0499, -0.0194,  0.0263,  0.0418,  0.0462, -0.0014,  0.0683, -0.0277,\n",
       "        -0.0013,  0.0566,  0.0067,  0.0272,  0.0114,  0.0468, -0.0615, -0.0442,\n",
       "         0.0349, -0.0512,  0.0541,  0.0290,  0.0231, -0.0601,  0.0083,  0.0548,\n",
       "         0.0318, -0.0067,  0.0308,  0.0350, -0.0356,  0.0021,  0.0465,  0.0656,\n",
       "         0.0105,  0.0483, -0.0421,  0.0421,  0.0144,  0.0606, -0.0239,  0.0252,\n",
       "        -0.0109, -0.0323, -0.0003,  0.0426, -0.0047,  0.0257,  0.0584, -0.0165,\n",
       "        -0.0048, -0.0250,  0.0242, -0.0282,  0.0287,  0.0499,  0.0359,  0.0106,\n",
       "        -0.0517, -0.0113,  0.0565, -0.0169, -0.0329, -0.0008, -0.0252, -0.0087,\n",
       "        -0.0547, -0.0396, -0.0291,  0.0264, -0.0358,  0.0413,  0.0116,  0.0133,\n",
       "         0.0028,  0.0687,  0.0237,  0.0201, -0.0505, -0.0522,  0.0393,  0.0368,\n",
       "         0.0341,  0.0288,  0.0791, -0.0171, -0.0488,  0.0344,  0.0309,  0.0310,\n",
       "         0.0322,  0.0176, -0.0057,  0.0349, -0.0188, -0.0295, -0.0151,  0.0306,\n",
       "        -0.0494,  0.0326, -0.0281,  0.0396,  0.0313,  0.0564,  0.0123,  0.0014,\n",
       "        -0.0169, -0.0190, -0.0002, -0.0097,  0.0244, -0.0321, -0.0511, -0.0384,\n",
       "        -0.0351, -0.0615,  0.0236,  0.0042,  0.0270, -0.0122, -0.0013,  0.0435,\n",
       "        -0.0135,  0.0465, -0.0339,  0.0490,  0.0300,  0.0203,  0.0050, -0.0004],\n",
       "       device='cuda:0')), ('fc2.weight', tensor([[-0.0279,  0.0541, -0.0667,  0.0655,  0.0323,  0.0982, -0.0916, -0.0241,\n",
       "          0.0377, -0.0873,  0.0473, -0.0153,  0.0289,  0.0392, -0.0848,  0.0416,\n",
       "         -0.0177, -0.0250,  0.0972,  0.1037, -0.0420,  0.0253,  0.0433, -0.0581,\n",
       "          0.0734, -0.0575,  0.0302, -0.1023,  0.0568,  0.0807,  0.0104,  0.0052,\n",
       "          0.0919, -0.0251, -0.0776,  0.0205,  0.0015,  0.0918, -0.0813,  0.0224,\n",
       "         -0.0730,  0.0906, -0.0803, -0.0426,  0.0829,  0.0534, -0.0499,  0.0053,\n",
       "         -0.0098,  0.1131,  0.0209, -0.0113, -0.0695,  0.0014, -0.0844,  0.0453,\n",
       "          0.0878, -0.0051, -0.0654,  0.0012, -0.0097, -0.0097,  0.0728,  0.0809,\n",
       "          0.0604, -0.0895, -0.0824,  0.0430,  0.0508, -0.0169, -0.0318, -0.0924,\n",
       "          0.0998, -0.0089,  0.0158,  0.1130, -0.0334,  0.0563, -0.0516,  0.0501,\n",
       "          0.0959, -0.1158,  0.0785,  0.0969,  0.0753,  0.0323,  0.0760,  0.0520,\n",
       "          0.0245,  0.0821, -0.0209, -0.1014, -0.1265,  0.0102,  0.0574, -0.0637,\n",
       "         -0.0282,  0.0367,  0.0109,  0.0299, -0.0726,  0.0875, -0.1001, -0.0911,\n",
       "          0.0306, -0.1037,  0.1016, -0.0458, -0.0311, -0.0407, -0.0049, -0.0374,\n",
       "         -0.0156,  0.0789,  0.0700,  0.0231,  0.0405, -0.0337, -0.0600,  0.0829,\n",
       "         -0.0734, -0.0575, -0.0484,  0.0506,  0.0076, -0.0366, -0.0370,  0.0638,\n",
       "          0.0390,  0.0362, -0.0191, -0.0294,  0.0520,  0.0493,  0.1057, -0.0335,\n",
       "          0.0610,  0.0028,  0.0667, -0.0947,  0.0266, -0.0214, -0.0384,  0.0701,\n",
       "         -0.0625,  0.0026, -0.0546,  0.0716,  0.0893,  0.0965,  0.0387, -0.0018,\n",
       "         -0.0809, -0.0609, -0.0669, -0.0882, -0.0696,  0.0373,  0.0701, -0.0835,\n",
       "         -0.1051,  0.0580,  0.1010, -0.0398, -0.0140, -0.0168, -0.0050, -0.1028,\n",
       "          0.0960,  0.1063,  0.1115,  0.0981, -0.0578, -0.0575,  0.0938,  0.0678,\n",
       "          0.0658,  0.0247,  0.0419,  0.0200, -0.0978,  0.0314,  0.0702,  0.0779,\n",
       "         -0.0465,  0.0829, -0.0763, -0.0013,  0.0631, -0.0611, -0.0039,  0.0065,\n",
       "          0.0605,  0.0912,  0.0208,  0.0951, -0.0021,  0.0431, -0.0376,  0.0709],\n",
       "        [ 0.0738, -0.0168,  0.0413, -0.0361, -0.0097, -0.0901, -0.0233, -0.0769,\n",
       "         -0.0875, -0.0267, -0.0181, -0.0784, -0.0410, -0.0588,  0.0557, -0.1034,\n",
       "          0.0458,  0.0354, -0.0048, -0.0894,  0.0477, -0.0522, -0.0805,  0.0440,\n",
       "         -0.0391,  0.0312, -0.0935, -0.0338, -0.0433, -0.0035,  0.0916, -0.1047,\n",
       "         -0.0377,  0.0990,  0.0023,  0.0908, -0.0590,  0.0348,  0.0648, -0.0508,\n",
       "          0.0665,  0.0158,  0.0519, -0.0360, -0.0014, -0.0454,  0.0472,  0.0935,\n",
       "          0.0909, -0.0491,  0.0812, -0.0710,  0.0731,  0.1004, -0.0313, -0.0651,\n",
       "         -0.0250, -0.0910,  0.0693, -0.0665,  0.0697,  0.0641, -0.0645, -0.0298,\n",
       "         -0.0735,  0.0253,  0.0482, -0.0722, -0.0630,  0.0839, -0.0813,  0.0266,\n",
       "         -0.0668,  0.0510,  0.0564, -0.0346,  0.0484, -0.0150,  0.0839, -0.0565,\n",
       "          0.0335,  0.1061, -0.0865, -0.0012, -0.0342, -0.0579,  0.0028, -0.0686,\n",
       "         -0.0614, -0.0871,  0.0771,  0.0408,  0.0196, -0.0364, -0.0555, -0.0168,\n",
       "          0.0585, -0.0431,  0.0534, -0.1064,  0.0084, -0.0176, -0.0014,  0.0683,\n",
       "         -0.0862,  0.1182, -0.1083,  0.1091,  0.0671,  0.0653, -0.0619,  0.0321,\n",
       "          0.0333, -0.0488, -0.0941, -0.0317, -0.0397,  0.0232,  0.0356, -0.0901,\n",
       "          0.0062, -0.0134, -0.0701, -0.0366, -0.0627,  0.0868,  0.0430,  0.0337,\n",
       "         -0.0714, -0.0604,  0.0583,  0.0927, -0.1019, -0.0258, -0.0960,  0.0030,\n",
       "         -0.0354, -0.0755, -0.1031, -0.0266,  0.0741,  0.0449,  0.0892, -0.0499,\n",
       "          0.0844,  0.1121,  0.0297,  0.0090, -0.0745, -0.0312, -0.0429,  0.0172,\n",
       "          0.1002,  0.0291,  0.0139,  0.0704,  0.0563, -0.0583, -0.0672,  0.0107,\n",
       "          0.0510, -0.0847, -0.0177,  0.0857,  0.0787,  0.0556, -0.1105,  0.0526,\n",
       "         -0.0604, -0.0884, -0.0410,  0.0100,  0.0672,  0.0554, -0.0700, -0.0354,\n",
       "         -0.0673,  0.0842, -0.0848, -0.0497, -0.0266, -0.0878, -0.0124, -0.0815,\n",
       "          0.0607,  0.0100,  0.0782,  0.0472, -0.0557,  0.0145, -0.1003, -0.0665,\n",
       "         -0.0371, -0.0251, -0.0979,  0.0069,  0.0707, -0.0888,  0.0948, -0.0889]],\n",
       "       device='cuda:0')), ('fc2.bias', tensor([-0.0239, -0.0395], device='cuda:0'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(model):\n",
    "    # Return model parameters as a list of NumPy ndarrays, excluding parameters of BN layers when using FedBN\n",
    "    return [val.cpu().numpy() for name, val in model.state_dict().items() if 'bn' not in name]\n",
    "\n",
    "def set_parameters(model, parameters):\n",
    "    # Set model parameters from a list of NumPy ndarrays\n",
    "    keys = [k for k in model.state_dict().keys() if 'bn' not in k]\n",
    "    params_dict = zip(keys, parameters)\n",
    "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader, configuration):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader,self.valloader,configuration, configuration['epochs'])\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader, configuration)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = SimpleCNN(dropout=configuration['dropout']).to(device)\n",
    "    trainloader = train_loaders[int(cid)]\n",
    "    valloader = val_loaders[int(cid)]\n",
    "    return FlowerClient(net, trainloader, valloader, configuration).to_client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n",
      "2024-07-31 14:51:18,365\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'object_store_memory': 51586743091.0, 'node:__internal_head__': 1.0, 'memory': 110369067213.0, 'node:192.168.1.146': 1.0, 'GPU': 2.0, 'accelerator_type:G': 1.0, 'CPU': 32.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 1/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 1: Training accuracy: 50.0.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 2/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 2: Training accuracy: 50.0.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 3/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 3: Training accuracy: 55.20072937011719.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 4/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 4: Training accuracy: 56.66058349609375.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 5/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 5: Training accuracy: 57.39051055908203.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 6/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 6: Training accuracy: 60.94890594482422.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 7/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 7: Training accuracy: 63.41240692138672.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 8/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 8: Training accuracy: 63.41240692138672.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 9/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 9: Training accuracy: 62.86496353149414.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 10/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 10: Training accuracy: 62.95620346069336.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 11/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 11: Training accuracy: 63.5036506652832.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 12/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 12: Training accuracy: 65.60218811035156.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 13/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 13: Training accuracy: 65.14598846435547.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 14/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 14: Training accuracy: 65.87591552734375.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 15/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 15: Training accuracy: 66.69708251953125.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 16/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 16: Training accuracy: 67.70072937011719.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 17/100\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 17: Training accuracy: 67.24452209472656.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 18: Training accuracy: 66.51459503173828.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 19: Training accuracy: 67.70072937011719.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 20: Training accuracy: 67.60948944091797.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 21: Training accuracy: 68.0656967163086.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 22: Training accuracy: 68.79562377929688.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 23: Training accuracy: 70.07299041748047.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 24: Training accuracy: 69.7080307006836.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186115)\u001b[0m \u001b[32m [repeated 348x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186115)\u001b[0m Epoch 89/100\u001b[32m [repeated 346x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186115)\u001b[0m Epoch 96: Training accuracy: 89.8721694946289.\u001b[32m [repeated 352x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186115)\u001b[0m \u001b[32m [repeated 390x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186115)\u001b[0m Epoch 82/100\u001b[32m [repeated 386x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186115)\u001b[0m Epoch 90: Training accuracy: 86.43067932128906.\u001b[32m [repeated 387x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 rounds in 13.84s\n",
      "\u001b[92mINFO \u001b[0m:      History (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t('\\tround 1: 0.2825636863708496\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 0.28727084398269653\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.2848720192909241\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 0.28376383781433107\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 5: 0.2822263717651367\\n')History (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 47.99471206665039),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 51.49836196899414),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 51.06040573120117),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 51.06040573120117),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 51.06040573120117)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "('\\tround 1: 0.2825636863708496\\n'\n",
       " '\\tround 2: 0.28727084398269653\\n'\n",
       " '\\tround 3: 0.2848720192909241\\n'\n",
       " '\\tround 4: 0.28376383781433107\\n'\n",
       " '\\tround 5: 0.2822263717651367\\n')History (metrics, distributed, evaluate):\n",
       "{'accuracy': [(1, 47.99471206665039),\n",
       "              (2, 51.49836196899414),\n",
       "              (3, 51.06040573120117),\n",
       "              (4, 51.06040573120117),\n",
       "              (5, 51.06040573120117)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m Epoch 100: Training accuracy: 89.87226104736328.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3186117)\u001b[0m [tensor(50., device='cuda:0'), tensor(50., device='cuda:0'), tensor(50., device='cuda:0'), tensor(56.5693, device='cuda:0'), tensor(79.1058, device='cuda:0'), tensor(80.1095, device='cuda:0'), tensor(83.5766, device='cuda:0'), tensor(83.1204, device='cuda:0'), tensor(83.9416, device='cuda:0'), tensor(83.9416, device='cuda:0'), tensor(84.8540, device='cuda:0'), tensor(84.9453, device='cuda:0'), tensor(84.5803, device='cuda:0'), tensor(85.0365, device='cuda:0'), tensor(84.5803, device='cuda:0'), tensor(85.1277, device='cuda:0'), tensor(85.8577, device='cuda:0'), tensor(85.7664, device='cuda:0'), tensor(85.5839, device='cuda:0'), tensor(86.4964, device='cuda:0'), tensor(86.5876, device='cuda:0'), tensor(86.7701, device='cuda:0'), tensor(85.9489, device='cuda:0'), tensor(86.5876, device='cuda:0'), tensor(87.3175, device='cuda:0'), tensor(86.3139, device='cuda:0'), tensor(87.1350, device='cuda:0'), tensor(87.0438, device='cuda:0'), tensor(87.2263, device='cuda:0'), tensor(87.3175, device='cuda:0'), tensor(87.0438, device='cuda:0'), tensor(87.4088, device='cuda:0'), tensor(87.5000, device='cuda:0'), tensor(87.7737, device='cuda:0'), tensor(87.9562, device='cuda:0'), tensor(87.9562, device='cuda:0'), tensor(87.6825, device='cuda:0'), tensor(87.2263, device='cuda:0'), tensor(88.0474, device='cuda:0'), tensor(87.5000, device='cuda:0'), tensor(87.9562, device='cuda:0'), tensor(87.4088, device='cuda:0'), tensor(87.2263, device='cuda:0'), tensor(88.5036, device='cuda:0'), tensor(88.6861, device='cuda:0'), tensor(88.1387, device='cuda:0'), tensor(88.3212, device='cuda:0'), tensor(88.7774, device='cuda:0'), tensor(88.3212, device='cuda:0'), tensor(87.9562, device='cuda:0'), tensor(88.7774, device='cuda:0'), tensor(88.6861, device='cuda:0'), tensor(88.7774, device='cuda:0'), tensor(88.4124, device='cuda:0'), tensor(88.4124, device='cuda:0'), tensor(87.5912, device='cuda:0'), tensor(88.7774, device='cuda:0'), tensor(88.8686, device='cuda:0'), tensor(86.7701, device='cuda:0'), tensor(89.3248, device='cuda:0'), tensor(88.4124, device='cuda:0'), tensor(89.5985, device='cuda:0'), tensor(88.9599, device='cuda:0'), tensor(88.5036, device='cuda:0'), tensor(89.0511, device='cuda:0'), tensor(89.1423, device='cuda:0'), tensor(89.1423, device='cuda:0'), tensor(88.8686, device='cuda:0'), tensor(88.8686, device='cuda:0'), tensor(89.0511, device='cuda:0'), tensor(89.1423, device='cuda:0'), tensor(89.3248, device='cuda:0'), tensor(89.2336, device='cuda:0'), tensor(89.1423, device='cuda:0'), tensor(89.3248, device='cuda:0'), tensor(88.6861, device='cuda:0'), tensor(89.4161, device='cuda:0'), tensor(89.4161, device='cuda:0'), tensor(89.5985, device='cuda:0'), tensor(89.1423, device='cuda:0'), tensor(89.7810, device='cuda:0'), tensor(89.6898, device='cuda:0'), tensor(89.9635, device='cuda:0'), tensor(90.1460, device='cuda:0'), tensor(90.0547, device='cuda:0'), tensor(90.2372, device='cuda:0'), tensor(89.4161, device='cuda:0'), tensor(89.1423, device='cuda:0'), tensor(90.3285, device='cuda:0'), tensor(89.6898, device='cuda:0'), tensor(90.1460, device='cuda:0'), tensor(89.7810, device='cuda:0'), tensor(89.2336, device='cuda:0'), tensor(89.7810, device='cuda:0'), tensor(89.6898, device='cuda:0'), tensor(88.5949, device='cuda:0'), tensor(90.0547, device='cuda:0'), tensor(89.9635, device='cuda:0'), tensor(89.7810, device='cuda:0'), tensor(89.8723, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "# client will be allocated 1x CPU and 0x GPUs\n",
    "if device.type == 'cuda':\n",
    "    # here we are assigning an entire GPU for each client.\n",
    "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0}\n",
    "    # Refer to our documentation for more details about Flower Simulations\n",
    "    # and how to setup these `client_resources`.\n",
    "def weighted_average(metrics) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,\n",
    "    fraction_evaluate=0.5,\n",
    "    min_fit_clients=2,\n",
    "    min_evaluate_clients=2,\n",
    "    min_available_clients=2,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=2,\n",
    "    config=fl.server.ServerConfig(num_rounds=50),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n",
      "2024-07-31 14:39:57,959\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 32.0, 'node:__internal_head__': 1.0, 'GPU': 2.0, 'accelerator_type:G': 1.0, 'object_store_memory': 51573732556.0, 'node:192.168.1.146': 1.0, 'memory': 110338709300.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=3175953)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3175953)\u001b[0m Epoch 1/1\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3175953)\u001b[0m Epoch 1: Training accuracy: 48.72262954711914.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=3175953)\u001b[0m [tensor(48.7226, device='cuda:0')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 rounds in 1.54s\n",
      "\u001b[92mINFO \u001b[0m:      History (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t('\\tround 1: 0.27688552141189576\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 0.2772903084754944\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.275903058052063\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 0.27777886390686035\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 5: 0.2755594849586487\\n')\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "('\\tround 1: 0.27688552141189576\\n'\n",
       " '\\tround 2: 0.2772903084754944\\n'\n",
       " '\\tround 3: 0.275903058052063\\n'\n",
       " '\\tround 4: 0.27777886390686035\\n'\n",
       " '\\tround 5: 0.2755594849586487\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client will be allocated 1x CPU and 0x GPUs\n",
    "if device.type == 'cuda':\n",
    "    # here we are assigning an entire GPU for each client.\n",
    "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0}\n",
    "    # Refer to our documentation for more details about Flower Simulations\n",
    "    # and how to setup these `client_resources`.\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=2,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=fl.server.strategy.FedAvg(),\n",
    "    client_resources=client_resources\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
