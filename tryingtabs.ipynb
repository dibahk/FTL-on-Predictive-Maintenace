{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_20884\\1565387505.py\", line 1, in <module>\n",
      "    a = torch.load('Datasets/NASA_turbofan_get_engine/data.pt')\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py\", line 1025, in load\n",
      "    return _load(opened_zipfile,\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py\", line 1446, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_utils.py\", line 202, in _rebuild_tensor_v2\n",
      "    tensor = _rebuild_tensor(storage, storage_offset, size, stride)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_utils.py\", line 180, in _rebuild_tensor\n",
      "    t = torch.empty((0,), dtype=storage.dtype, device=storage._untyped_storage.device)\n",
      "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_utils.py:180: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  t = torch.empty((0,), dtype=storage.dtype, device=storage._untyped_storage.device)\n"
     ]
    }
   ],
   "source": [
    "a = torch.load('Datasets/NASA_turbofan_get_engine/data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236, 2400)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_2390</th>\n",
       "      <th>feature_2391</th>\n",
       "      <th>feature_2392</th>\n",
       "      <th>feature_2393</th>\n",
       "      <th>feature_2394</th>\n",
       "      <th>feature_2395</th>\n",
       "      <th>feature_2396</th>\n",
       "      <th>feature_2397</th>\n",
       "      <th>feature_2398</th>\n",
       "      <th>feature_2399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.669983</td>\n",
       "      <td>642.640015</td>\n",
       "      <td>1582.969971</td>\n",
       "      <td>1402.719971</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.610001</td>\n",
       "      <td>554.260010</td>\n",
       "      <td>...</td>\n",
       "      <td>519.809998</td>\n",
       "      <td>2388.209961</td>\n",
       "      <td>8175.569824</td>\n",
       "      <td>8.5365</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.430000</td>\n",
       "      <td>23.084801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.669983</td>\n",
       "      <td>642.229980</td>\n",
       "      <td>1587.880005</td>\n",
       "      <td>1398.170044</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>554.710022</td>\n",
       "      <td>...</td>\n",
       "      <td>521.090027</td>\n",
       "      <td>2388.050049</td>\n",
       "      <td>8136.799805</td>\n",
       "      <td>8.4101</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.930000</td>\n",
       "      <td>23.392599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.669983</td>\n",
       "      <td>642.799988</td>\n",
       "      <td>1590.510010</td>\n",
       "      <td>1406.089966</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.610001</td>\n",
       "      <td>553.830017</td>\n",
       "      <td>...</td>\n",
       "      <td>519.859985</td>\n",
       "      <td>2388.159912</td>\n",
       "      <td>8212.750000</td>\n",
       "      <td>8.5209</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.450001</td>\n",
       "      <td>23.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.669983</td>\n",
       "      <td>641.859985</td>\n",
       "      <td>1583.300049</td>\n",
       "      <td>1389.869995</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.610001</td>\n",
       "      <td>554.510010</td>\n",
       "      <td>...</td>\n",
       "      <td>521.469971</td>\n",
       "      <td>2387.989990</td>\n",
       "      <td>8158.850098</td>\n",
       "      <td>8.4577</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.889999</td>\n",
       "      <td>23.370399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.669983</td>\n",
       "      <td>642.119995</td>\n",
       "      <td>1587.000000</td>\n",
       "      <td>1408.800049</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.610001</td>\n",
       "      <td>553.729980</td>\n",
       "      <td>...</td>\n",
       "      <td>519.099976</td>\n",
       "      <td>2388.239990</td>\n",
       "      <td>8145.750000</td>\n",
       "      <td>8.5162</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.459999</td>\n",
       "      <td>23.059601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2   feature_3   feature_4    feature_5  \\\n",
       "0     0.0024     0.0002      100.0  518.669983  642.640015  1582.969971   \n",
       "1     0.0007    -0.0002      100.0  518.669983  642.229980  1587.880005   \n",
       "2     0.0009    -0.0004      100.0  518.669983  642.799988  1590.510010   \n",
       "3     0.0009    -0.0004      100.0  518.669983  641.859985  1583.300049   \n",
       "4     0.0002     0.0001      100.0  518.669983  642.119995  1587.000000   \n",
       "\n",
       "     feature_6  feature_7  feature_8   feature_9  ...  feature_2390  \\\n",
       "0  1402.719971      14.62  21.610001  554.260010  ...    519.809998   \n",
       "1  1398.170044      14.62  21.600000  554.710022  ...    521.090027   \n",
       "2  1406.089966      14.62  21.610001  553.830017  ...    519.859985   \n",
       "3  1389.869995      14.62  21.610001  554.510010  ...    521.469971   \n",
       "4  1408.800049      14.62  21.610001  553.729980  ...    519.099976   \n",
       "\n",
       "   feature_2391  feature_2392  feature_2393  feature_2394  feature_2395  \\\n",
       "0   2388.209961   8175.569824        8.5365          0.03         398.0   \n",
       "1   2388.050049   8136.799805        8.4101          0.03         392.0   \n",
       "2   2388.159912   8212.750000        8.5209          0.03         397.0   \n",
       "3   2387.989990   8158.850098        8.4577          0.03         393.0   \n",
       "4   2388.239990   8145.750000        8.5162          0.03         396.0   \n",
       "\n",
       "   feature_2396  feature_2397  feature_2398  feature_2399  \n",
       "0        2388.0         100.0     38.430000     23.084801  \n",
       "1        2388.0         100.0     38.930000     23.392599  \n",
       "2        2388.0         100.0     38.450001     23.029600  \n",
       "3        2388.0         100.0     38.889999     23.370399  \n",
       "4        2388.0         100.0     38.459999     23.059601  \n",
       "\n",
       "[5 rows x 2400 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten the tensor to size 236x2400\n",
    "flattened_tensor = a.view(236, -1)\n",
    "\n",
    "# Convert to pandas DataFrame directly from the tensor\n",
    "df = pd.DataFrame(flattened_tensor.tolist(), columns=[f'feature_{i}' for i in range(flattened_tensor.shape[1])])\n",
    "\n",
    "# Print the DataFrame shape to verify\n",
    "print(df.shape)  # Expected output: (236, 2400)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.load('Datasets/NASA_turbofan_get_engine/label.pt')\n",
    "df['target'] = label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = df.corr()['target'].sort_values(ascending=False).drop(['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_2392    0.326399\n",
       "feature_2248    0.272588\n",
       "feature_2152    0.243654\n",
       "feature_1864    0.233558\n",
       "feature_2368    0.227137\n",
       "                  ...   \n",
       "feature_2003    0.102093\n",
       "feature_1789    0.101883\n",
       "feature_781     0.101636\n",
       "feature_1853    0.101444\n",
       "feature_1710    0.100067\n",
       "Name: target, Length: 101, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor[cor>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1429"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cor[cor>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2401"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cor[cor>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.load('Datasets/NASA_turbofan_get_engine/label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([236])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.load('Datasets\\Microsoft_Azure_Predictive_Maintenance\\Preprocessed\\data_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66, 100, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               col1      col2      col3      col4\n",
      "block row                                        \n",
      "0     0    0.048543  0.941427  0.574083  0.836976\n",
      "      1    0.820031  0.965739  0.573246  0.191334\n",
      "      2    0.548488  0.691164  0.971250  0.183431\n",
      "1     0    0.177088  0.774562  0.948008  0.651475\n",
      "      1    0.737338  0.502554  0.723149  0.466648\n",
      "      2    0.402492  0.140235  0.536015  0.259938\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample 3D data\n",
    "data = np.random.rand(2, 3, 4)  # 2 blocks, 3 rows, 4 columns\n",
    "\n",
    "# Create a MultiIndex\n",
    "index = pd.MultiIndex.from_product([[0, 1], range(3)], names=['block', 'row'])\n",
    "columns = ['col1', 'col2', 'col3', 'col4']\n",
    "\n",
    "# Create DataFrame with MultiIndex\n",
    "df = pd.DataFrame(data.reshape(6, 4), index=index, columns=columns)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtype)\n",
    "print(y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_train).sum())\n",
    "print(np.isnan(X_test).sum())\n",
    "print(np.isinf(X_train).sum())\n",
    "print(np.isinf(X_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample 3D data\n",
    "num_samples = 100\n",
    "num_timesteps = 10\n",
    "num_features_per_timestep = 3\n",
    "data = np.array(np.random.rand(num_samples, num_timesteps, num_features_per_timestep), dtype=np.float32)\n",
    "\n",
    "# Target variable\n",
    "target = np.array(np.random.randint(0, 2, num_samples), dtype=np.int64)\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = data.reshape(num_samples, -1)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data, columns=[f'time_{t}_feature_{f}' for t in range(num_timesteps) for f in range(num_features_per_timestep)])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 1  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 2  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 3  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 4  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 5  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 6  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 7  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 8  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 9  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:01s\n",
      "epoch 10 | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_accuracy = 0.65\n",
      "Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train TabNet model\n",
    "model = TabNetClassifier()\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.81048 | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 1  | loss: 0.80109 | val_0_accuracy: 0.3     |  0:00:00s\n",
      "epoch 2  | loss: 0.70373 | val_0_accuracy: 0.5     |  0:00:00s\n",
      "epoch 3  | loss: 0.79848 | val_0_accuracy: 0.55    |  0:00:00s\n",
      "epoch 4  | loss: 0.75651 | val_0_accuracy: 0.6     |  0:00:00s\n",
      "epoch 5  | loss: 0.74417 | val_0_accuracy: 0.6     |  0:00:00s\n",
      "epoch 6  | loss: 0.68905 | val_0_accuracy: 0.6     |  0:00:00s\n",
      "epoch 7  | loss: 0.68833 | val_0_accuracy: 0.5     |  0:00:00s\n",
      "epoch 8  | loss: 0.68793 | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 9  | loss: 0.69625 | val_0_accuracy: 0.55    |  0:00:01s\n",
      "epoch 10 | loss: 0.68338 | val_0_accuracy: 0.5     |  0:00:01s\n",
      "epoch 11 | loss: 0.65762 | val_0_accuracy: 0.45    |  0:00:01s\n",
      "epoch 12 | loss: 0.66475 | val_0_accuracy: 0.3     |  0:00:01s\n",
      "epoch 13 | loss: 0.65605 | val_0_accuracy: 0.4     |  0:00:01s\n",
      "epoch 14 | loss: 0.63367 | val_0_accuracy: 0.5     |  0:00:01s\n",
      "epoch 15 | loss: 0.68532 | val_0_accuracy: 0.5     |  0:00:02s\n",
      "epoch 16 | loss: 0.64607 | val_0_accuracy: 0.5     |  0:00:02s\n",
      "epoch 17 | loss: 0.65317 | val_0_accuracy: 0.45    |  0:00:02s\n",
      "epoch 18 | loss: 0.68495 | val_0_accuracy: 0.5     |  0:00:02s\n",
      "epoch 19 | loss: 0.63463 | val_0_accuracy: 0.55    |  0:00:02s\n",
      "epoch 20 | loss: 0.63862 | val_0_accuracy: 0.45    |  0:00:02s\n",
      "epoch 21 | loss: 0.57162 | val_0_accuracy: 0.45    |  0:00:03s\n",
      "epoch 22 | loss: 0.62818 | val_0_accuracy: 0.5     |  0:00:03s\n",
      "epoch 23 | loss: 0.65606 | val_0_accuracy: 0.55    |  0:00:03s\n",
      "epoch 24 | loss: 0.64308 | val_0_accuracy: 0.55    |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_accuracy = 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Class distribution in training set: [37 43]\n",
      "Class distribution in test set: [10 10]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "# Sample 3D data\n",
    "num_samples = 100\n",
    "num_timesteps = 10\n",
    "num_features_per_timestep = 3\n",
    "data = np.random.rand(num_samples, num_timesteps, num_features_per_timestep).astype(np.float32)\n",
    "\n",
    "# Target variable\n",
    "target = np.random.randint(0, 2, num_samples).astype(np.int64)\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = data.reshape(num_samples, -1)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data, columns=[f'time_{t}_feature_{f}' for t in range(num_timesteps) for f in range(num_features_per_timestep)])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "# Initialize and train TabNet model with more epochs and adjusted parameters\n",
    "model = TabNetClassifier(n_d=8, n_a=8, n_steps=3, gamma=1.5, lambda_sparse=1e-3, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2), mask_type='sparsemax')\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=200,  # Increase the number of epochs\n",
    "    patience=20,  # Allow early stopping with patience\n",
    "    batch_size=32,\n",
    "    virtual_batch_size=16\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"Class distribution in training set: {np.bincount(y_train)}\")\n",
    "print(f\"Class distribution in test set: {np.bincount(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 1  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 2  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 3  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 4  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 5  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 6  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 7  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 8  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 9  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 10 | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_accuracy = 0.45\n",
      "Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample 3D data\n",
    "num_samples = 100\n",
    "num_timesteps = 10\n",
    "num_features_per_timestep = 3\n",
    "data = np.array(np.random.rand(num_samples, num_timesteps, num_features_per_timestep), dtype=np.float32)\n",
    "\n",
    "# Target variable\n",
    "target = np.array(np.random.randint(0, 2, num_samples), dtype=np.int64)\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = data.reshape(num_samples, -1)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data, columns=[f'time_{t}_feature_{f}' for t in range(num_timesteps) for f in range(num_features_per_timestep)])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = np.array(scaler.fit_transform(X_train))\n",
    "X_test = np.array(scaler.transform(X_test))\n",
    "\n",
    "# Initialize and train TabNet model\n",
    "# tabnet_params = {\n",
    "#                  \"optimizer_fn\":torch.optim.Adam,\n",
    "#                  \"optimizer_params\":dict(lr=2e-2),\n",
    "#                  \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
    "#                                  \"gamma\":0.9},\n",
    "#                  \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "#                  \"mask_type\":'entmax' # \"sparsemax\"\n",
    "#                 }\n",
    "\n",
    "# clf = TabNetClassifier(**tabnet_params\n",
    "#                       )\n",
    "model = TabNetClassifier()\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10676\\1115469300.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "df.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
