{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load('Datasets/NASA_turbofan_get_engine/data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([236, 100, 24])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.load('Datasets/NASA_turbofan_get_engine/label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([236])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.load('Datasets\\Microsoft_Azure_Predictive_Maintenance\\Preprocessed\\data_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66, 100, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               col1      col2      col3      col4\n",
      "block row                                        \n",
      "0     0    0.048543  0.941427  0.574083  0.836976\n",
      "      1    0.820031  0.965739  0.573246  0.191334\n",
      "      2    0.548488  0.691164  0.971250  0.183431\n",
      "1     0    0.177088  0.774562  0.948008  0.651475\n",
      "      1    0.737338  0.502554  0.723149  0.466648\n",
      "      2    0.402492  0.140235  0.536015  0.259938\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample 3D data\n",
    "data = np.random.rand(2, 3, 4)  # 2 blocks, 3 rows, 4 columns\n",
    "\n",
    "# Create a MultiIndex\n",
    "index = pd.MultiIndex.from_product([[0, 1], range(3)], names=['block', 'row'])\n",
    "columns = ['col1', 'col2', 'col3', 'col4']\n",
    "\n",
    "# Create DataFrame with MultiIndex\n",
    "df = pd.DataFrame(data.reshape(6, 4), index=index, columns=columns)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xarray\n",
      "  Downloading xarray-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xarray) (2.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xarray) (24.1)\n",
      "Requirement already satisfied: pandas>=2.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xarray) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0->xarray) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0->xarray) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0->xarray) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0->xarray) (1.16.0)\n",
      "Downloading xarray-2024.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.2 MB 660.6 kB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.2/1.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.2 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.0/1.2 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 4.9 MB/s eta 0:00:00\n",
      "Installing collected packages: xarray\n",
      "Successfully installed xarray-2024.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\Asus\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (block: 2, row: 3, col: 4)> Size: 192B\n",
      "array([[[0.58159065, 0.54735392, 0.17235134, 0.02773692],\n",
      "        [0.1629811 , 0.73701086, 0.72022467, 0.73334446],\n",
      "        [0.88176207, 0.50226254, 0.61140714, 0.26824952]],\n",
      "\n",
      "       [[0.08607223, 0.89167224, 0.06779202, 0.722981  ],\n",
      "        [0.44831074, 0.23478806, 0.4940223 , 0.04964736],\n",
      "        [0.30673853, 0.57096379, 0.23923296, 0.25237048]]])\n",
      "Coordinates:\n",
      "  * block    (block) int64 16B 0 1\n",
      "  * row      (row) int64 24B 0 1 2\n",
      "  * col      (col) <U4 64B 'col1' 'col2' 'col3' 'col4'\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Sample 3D data\n",
    "data = np.random.rand(2, 3, 4)  # 2 blocks, 3 rows, 4 columns\n",
    "\n",
    "# Create an xarray DataArray\n",
    "xr_data = xr.DataArray(data, dims=['block', 'row', 'col'], coords={'block': [0, 1], 'row': [0, 1, 2], 'col': ['col1', 'col2', 'col3', 'col4']})\n",
    "print(xr_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_0_feature_0</th>\n",
       "      <th>time_0_feature_1</th>\n",
       "      <th>time_0_feature_2</th>\n",
       "      <th>time_1_feature_0</th>\n",
       "      <th>time_1_feature_1</th>\n",
       "      <th>time_1_feature_2</th>\n",
       "      <th>time_2_feature_0</th>\n",
       "      <th>time_2_feature_1</th>\n",
       "      <th>time_2_feature_2</th>\n",
       "      <th>time_3_feature_0</th>\n",
       "      <th>...</th>\n",
       "      <th>time_6_feature_2</th>\n",
       "      <th>time_7_feature_0</th>\n",
       "      <th>time_7_feature_1</th>\n",
       "      <th>time_7_feature_2</th>\n",
       "      <th>time_8_feature_0</th>\n",
       "      <th>time_8_feature_1</th>\n",
       "      <th>time_8_feature_2</th>\n",
       "      <th>time_9_feature_0</th>\n",
       "      <th>time_9_feature_1</th>\n",
       "      <th>time_9_feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.172981</td>\n",
       "      <td>0.731384</td>\n",
       "      <td>0.727358</td>\n",
       "      <td>0.750327</td>\n",
       "      <td>0.100415</td>\n",
       "      <td>0.047897</td>\n",
       "      <td>0.844132</td>\n",
       "      <td>0.403214</td>\n",
       "      <td>0.590008</td>\n",
       "      <td>0.787187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455074</td>\n",
       "      <td>0.379844</td>\n",
       "      <td>0.067821</td>\n",
       "      <td>0.198931</td>\n",
       "      <td>0.864818</td>\n",
       "      <td>0.575765</td>\n",
       "      <td>0.870327</td>\n",
       "      <td>0.202259</td>\n",
       "      <td>0.552507</td>\n",
       "      <td>0.391217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.938696</td>\n",
       "      <td>0.286412</td>\n",
       "      <td>0.635796</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>0.373356</td>\n",
       "      <td>0.531941</td>\n",
       "      <td>0.926684</td>\n",
       "      <td>0.543687</td>\n",
       "      <td>0.509551</td>\n",
       "      <td>0.337081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951972</td>\n",
       "      <td>0.471090</td>\n",
       "      <td>0.120710</td>\n",
       "      <td>0.330607</td>\n",
       "      <td>0.363527</td>\n",
       "      <td>0.812003</td>\n",
       "      <td>0.711536</td>\n",
       "      <td>0.610565</td>\n",
       "      <td>0.070026</td>\n",
       "      <td>0.247356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.383353</td>\n",
       "      <td>0.556842</td>\n",
       "      <td>0.051109</td>\n",
       "      <td>0.140533</td>\n",
       "      <td>0.265066</td>\n",
       "      <td>0.846911</td>\n",
       "      <td>0.128447</td>\n",
       "      <td>0.520037</td>\n",
       "      <td>0.263855</td>\n",
       "      <td>0.621864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063473</td>\n",
       "      <td>0.792631</td>\n",
       "      <td>0.451967</td>\n",
       "      <td>0.637843</td>\n",
       "      <td>0.833191</td>\n",
       "      <td>0.149917</td>\n",
       "      <td>0.288204</td>\n",
       "      <td>0.120591</td>\n",
       "      <td>0.296825</td>\n",
       "      <td>0.724611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.782445</td>\n",
       "      <td>0.801295</td>\n",
       "      <td>0.261055</td>\n",
       "      <td>0.242467</td>\n",
       "      <td>0.165222</td>\n",
       "      <td>0.352040</td>\n",
       "      <td>0.447922</td>\n",
       "      <td>0.861160</td>\n",
       "      <td>0.929545</td>\n",
       "      <td>0.613021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851192</td>\n",
       "      <td>0.929010</td>\n",
       "      <td>0.321081</td>\n",
       "      <td>0.536179</td>\n",
       "      <td>0.949140</td>\n",
       "      <td>0.138941</td>\n",
       "      <td>0.534887</td>\n",
       "      <td>0.554001</td>\n",
       "      <td>0.905818</td>\n",
       "      <td>0.917202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.546811</td>\n",
       "      <td>0.383745</td>\n",
       "      <td>0.313320</td>\n",
       "      <td>0.054605</td>\n",
       "      <td>0.663223</td>\n",
       "      <td>0.753829</td>\n",
       "      <td>0.484016</td>\n",
       "      <td>0.310179</td>\n",
       "      <td>0.601815</td>\n",
       "      <td>0.998086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435444</td>\n",
       "      <td>0.072083</td>\n",
       "      <td>0.529528</td>\n",
       "      <td>0.373175</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>0.952196</td>\n",
       "      <td>0.013558</td>\n",
       "      <td>0.956507</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.175525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_0_feature_0  time_0_feature_1  time_0_feature_2  time_1_feature_0  \\\n",
       "0          0.172981          0.731384          0.727358          0.750327   \n",
       "1          0.938696          0.286412          0.635796          0.705303   \n",
       "2          0.383353          0.556842          0.051109          0.140533   \n",
       "3          0.782445          0.801295          0.261055          0.242467   \n",
       "4          0.546811          0.383745          0.313320          0.054605   \n",
       "\n",
       "   time_1_feature_1  time_1_feature_2  time_2_feature_0  time_2_feature_1  \\\n",
       "0          0.100415          0.047897          0.844132          0.403214   \n",
       "1          0.373356          0.531941          0.926684          0.543687   \n",
       "2          0.265066          0.846911          0.128447          0.520037   \n",
       "3          0.165222          0.352040          0.447922          0.861160   \n",
       "4          0.663223          0.753829          0.484016          0.310179   \n",
       "\n",
       "   time_2_feature_2  time_3_feature_0  ...  time_6_feature_2  \\\n",
       "0          0.590008          0.787187  ...          0.455074   \n",
       "1          0.509551          0.337081  ...          0.951972   \n",
       "2          0.263855          0.621864  ...          0.063473   \n",
       "3          0.929545          0.613021  ...          0.851192   \n",
       "4          0.601815          0.998086  ...          0.435444   \n",
       "\n",
       "   time_7_feature_0  time_7_feature_1  time_7_feature_2  time_8_feature_0  \\\n",
       "0          0.379844          0.067821          0.198931          0.864818   \n",
       "1          0.471090          0.120710          0.330607          0.363527   \n",
       "2          0.792631          0.451967          0.637843          0.833191   \n",
       "3          0.929010          0.321081          0.536179          0.949140   \n",
       "4          0.072083          0.529528          0.373175          0.039641   \n",
       "\n",
       "   time_8_feature_1  time_8_feature_2  time_9_feature_0  time_9_feature_1  \\\n",
       "0          0.575765          0.870327          0.202259          0.552507   \n",
       "1          0.812003          0.711536          0.610565          0.070026   \n",
       "2          0.149917          0.288204          0.120591          0.296825   \n",
       "3          0.138941          0.534887          0.554001          0.905818   \n",
       "4          0.952196          0.013558          0.956507          0.108800   \n",
       "\n",
       "   time_9_feature_2  \n",
       "0          0.391217  \n",
       "1          0.247356  \n",
       "2          0.724611  \n",
       "3          0.917202  \n",
       "4          0.175525  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtype)\n",
    "print(y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_train).sum())\n",
    "print(np.isnan(X_test).sum())\n",
    "print(np.isinf(X_train).sum())\n",
    "print(np.isinf(X_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample 3D data\n",
    "num_samples = 100\n",
    "num_timesteps = 10\n",
    "num_features_per_timestep = 3\n",
    "data = np.array(np.random.rand(num_samples, num_timesteps, num_features_per_timestep), dtype=np.float32)\n",
    "\n",
    "# Target variable\n",
    "target = np.array(np.random.randint(0, 2, num_samples), dtype=np.int64)\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = data.reshape(num_samples, -1)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data, columns=[f'time_{t}_feature_{f}' for t in range(num_timesteps) for f in range(num_features_per_timestep)])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 1  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 2  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 3  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 4  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 5  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 6  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 7  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 8  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:00s\n",
      "epoch 9  | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:01s\n",
      "epoch 10 | loss: 0.0     | val_0_accuracy: 0.65    |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_accuracy = 0.65\n",
      "Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train TabNet model\n",
    "model = TabNetClassifier()\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.81048 | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 1  | loss: 0.80109 | val_0_accuracy: 0.3     |  0:00:00s\n",
      "epoch 2  | loss: 0.70373 | val_0_accuracy: 0.5     |  0:00:00s\n",
      "epoch 3  | loss: 0.79848 | val_0_accuracy: 0.55    |  0:00:00s\n",
      "epoch 4  | loss: 0.75651 | val_0_accuracy: 0.6     |  0:00:00s\n",
      "epoch 5  | loss: 0.74417 | val_0_accuracy: 0.6     |  0:00:00s\n",
      "epoch 6  | loss: 0.68905 | val_0_accuracy: 0.6     |  0:00:00s\n",
      "epoch 7  | loss: 0.68833 | val_0_accuracy: 0.5     |  0:00:00s\n",
      "epoch 8  | loss: 0.68793 | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 9  | loss: 0.69625 | val_0_accuracy: 0.55    |  0:00:01s\n",
      "epoch 10 | loss: 0.68338 | val_0_accuracy: 0.5     |  0:00:01s\n",
      "epoch 11 | loss: 0.65762 | val_0_accuracy: 0.45    |  0:00:01s\n",
      "epoch 12 | loss: 0.66475 | val_0_accuracy: 0.3     |  0:00:01s\n",
      "epoch 13 | loss: 0.65605 | val_0_accuracy: 0.4     |  0:00:01s\n",
      "epoch 14 | loss: 0.63367 | val_0_accuracy: 0.5     |  0:00:01s\n",
      "epoch 15 | loss: 0.68532 | val_0_accuracy: 0.5     |  0:00:02s\n",
      "epoch 16 | loss: 0.64607 | val_0_accuracy: 0.5     |  0:00:02s\n",
      "epoch 17 | loss: 0.65317 | val_0_accuracy: 0.45    |  0:00:02s\n",
      "epoch 18 | loss: 0.68495 | val_0_accuracy: 0.5     |  0:00:02s\n",
      "epoch 19 | loss: 0.63463 | val_0_accuracy: 0.55    |  0:00:02s\n",
      "epoch 20 | loss: 0.63862 | val_0_accuracy: 0.45    |  0:00:02s\n",
      "epoch 21 | loss: 0.57162 | val_0_accuracy: 0.45    |  0:00:03s\n",
      "epoch 22 | loss: 0.62818 | val_0_accuracy: 0.5     |  0:00:03s\n",
      "epoch 23 | loss: 0.65606 | val_0_accuracy: 0.55    |  0:00:03s\n",
      "epoch 24 | loss: 0.64308 | val_0_accuracy: 0.55    |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_accuracy = 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Class distribution in training set: [37 43]\n",
      "Class distribution in test set: [10 10]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "# Sample 3D data\n",
    "num_samples = 100\n",
    "num_timesteps = 10\n",
    "num_features_per_timestep = 3\n",
    "data = np.random.rand(num_samples, num_timesteps, num_features_per_timestep).astype(np.float32)\n",
    "\n",
    "# Target variable\n",
    "target = np.random.randint(0, 2, num_samples).astype(np.int64)\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = data.reshape(num_samples, -1)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data, columns=[f'time_{t}_feature_{f}' for t in range(num_timesteps) for f in range(num_features_per_timestep)])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "# Initialize and train TabNet model with more epochs and adjusted parameters\n",
    "model = TabNetClassifier(n_d=8, n_a=8, n_steps=3, gamma=1.5, lambda_sparse=1e-3, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2), mask_type='sparsemax')\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=200,  # Increase the number of epochs\n",
    "    patience=20,  # Allow early stopping with patience\n",
    "    batch_size=32,\n",
    "    virtual_batch_size=16\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"Class distribution in training set: {np.bincount(y_train)}\")\n",
    "print(f\"Class distribution in test set: {np.bincount(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 1  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 2  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 3  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 4  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 5  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 6  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 7  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 8  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 9  | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "epoch 10 | loss: 0.0     | val_0_accuracy: 0.45    |  0:00:00s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_accuracy = 0.45\n",
      "Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diba/miniconda3/envs/FTL/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample 3D data\n",
    "num_samples = 100\n",
    "num_timesteps = 10\n",
    "num_features_per_timestep = 3\n",
    "data = np.array(np.random.rand(num_samples, num_timesteps, num_features_per_timestep), dtype=np.float32)\n",
    "\n",
    "# Target variable\n",
    "target = np.array(np.random.randint(0, 2, num_samples), dtype=np.int64)\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = data.reshape(num_samples, -1)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data, columns=[f'time_{t}_feature_{f}' for t in range(num_timesteps) for f in range(num_features_per_timestep)])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = np.array(scaler.fit_transform(X_train))\n",
    "X_test = np.array(scaler.transform(X_test))\n",
    "\n",
    "# Initialize and train TabNet model\n",
    "# tabnet_params = {\n",
    "#                  \"optimizer_fn\":torch.optim.Adam,\n",
    "#                  \"optimizer_params\":dict(lr=2e-2),\n",
    "#                  \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
    "#                                  \"gamma\":0.9},\n",
    "#                  \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "#                  \"mask_type\":'entmax' # \"sparsemax\"\n",
    "#                 }\n",
    "\n",
    "# clf = TabNetClassifier(**tabnet_params\n",
    "#                       )\n",
    "model = TabNetClassifier()\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10676\\1115469300.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "df.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
