{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load('Datasets/NASA_turbofan_get_engine/data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([236, 100, 24])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.load('Datasets/NASA_turbofan_get_engine/label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([236])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.load('Datasets\\Microsoft_Azure_Predictive_Maintenance\\Preprocessed\\data_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66, 100, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               col1      col2      col3      col4\n",
      "block row                                        \n",
      "0     0    0.048543  0.941427  0.574083  0.836976\n",
      "      1    0.820031  0.965739  0.573246  0.191334\n",
      "      2    0.548488  0.691164  0.971250  0.183431\n",
      "1     0    0.177088  0.774562  0.948008  0.651475\n",
      "      1    0.737338  0.502554  0.723149  0.466648\n",
      "      2    0.402492  0.140235  0.536015  0.259938\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample 3D data\n",
    "data = np.random.rand(2, 3, 4)  # 2 blocks, 3 rows, 4 columns\n",
    "\n",
    "# Create a MultiIndex\n",
    "index = pd.MultiIndex.from_product([[0, 1], range(3)], names=['block', 'row'])\n",
    "columns = ['col1', 'col2', 'col3', 'col4']\n",
    "\n",
    "# Create DataFrame with MultiIndex\n",
    "df = pd.DataFrame(data.reshape(6, 4), index=index, columns=columns)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xarray\n",
      "  Downloading xarray-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xarray) (2.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xarray) (24.1)\n",
      "Requirement already satisfied: pandas>=2.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xarray) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0->xarray) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0->xarray) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0->xarray) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0->xarray) (1.16.0)\n",
      "Downloading xarray-2024.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.2 MB 660.6 kB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.2/1.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.2 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.0/1.2 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 4.9 MB/s eta 0:00:00\n",
      "Installing collected packages: xarray\n",
      "Successfully installed xarray-2024.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\Asus\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (block: 2, row: 3, col: 4)> Size: 192B\n",
      "array([[[0.58159065, 0.54735392, 0.17235134, 0.02773692],\n",
      "        [0.1629811 , 0.73701086, 0.72022467, 0.73334446],\n",
      "        [0.88176207, 0.50226254, 0.61140714, 0.26824952]],\n",
      "\n",
      "       [[0.08607223, 0.89167224, 0.06779202, 0.722981  ],\n",
      "        [0.44831074, 0.23478806, 0.4940223 , 0.04964736],\n",
      "        [0.30673853, 0.57096379, 0.23923296, 0.25237048]]])\n",
      "Coordinates:\n",
      "  * block    (block) int64 16B 0 1\n",
      "  * row      (row) int64 24B 0 1 2\n",
      "  * col      (col) <U4 64B 'col1' 'col2' 'col3' 'col4'\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Sample 3D data\n",
    "data = np.random.rand(2, 3, 4)  # 2 blocks, 3 rows, 4 columns\n",
    "\n",
    "# Create an xarray DataArray\n",
    "xr_data = xr.DataArray(data, dims=['block', 'row', 'col'], coords={'block': [0, 1], 'row': [0, 1, 2], 'col': ['col1', 'col2', 'col3', 'col4']})\n",
    "print(xr_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample 3D data\n",
    "num_samples = 100\n",
    "num_timesteps = 10\n",
    "num_features_per_timestep = 3\n",
    "data = np.random.rand(num_samples, num_timesteps, num_features_per_timestep)\n",
    "\n",
    "# Target variable\n",
    "target = np.random.randint(0, 2, num_samples)\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = data.reshape(num_samples, -1)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data.astype(np.float32), columns=[f'time_{t}_feature_{f}' for t in range(num_timesteps) for f in range(num_features_per_timestep)])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_0_feature_0</th>\n",
       "      <th>time_0_feature_1</th>\n",
       "      <th>time_0_feature_2</th>\n",
       "      <th>time_1_feature_0</th>\n",
       "      <th>time_1_feature_1</th>\n",
       "      <th>time_1_feature_2</th>\n",
       "      <th>time_2_feature_0</th>\n",
       "      <th>time_2_feature_1</th>\n",
       "      <th>time_2_feature_2</th>\n",
       "      <th>time_3_feature_0</th>\n",
       "      <th>...</th>\n",
       "      <th>time_6_feature_2</th>\n",
       "      <th>time_7_feature_0</th>\n",
       "      <th>time_7_feature_1</th>\n",
       "      <th>time_7_feature_2</th>\n",
       "      <th>time_8_feature_0</th>\n",
       "      <th>time_8_feature_1</th>\n",
       "      <th>time_8_feature_2</th>\n",
       "      <th>time_9_feature_0</th>\n",
       "      <th>time_9_feature_1</th>\n",
       "      <th>time_9_feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.289801</td>\n",
       "      <td>0.471057</td>\n",
       "      <td>0.781017</td>\n",
       "      <td>0.841905</td>\n",
       "      <td>0.331801</td>\n",
       "      <td>0.229895</td>\n",
       "      <td>0.498487</td>\n",
       "      <td>0.991321</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.693752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714224</td>\n",
       "      <td>0.856971</td>\n",
       "      <td>0.828770</td>\n",
       "      <td>0.899247</td>\n",
       "      <td>0.358396</td>\n",
       "      <td>0.281386</td>\n",
       "      <td>0.226141</td>\n",
       "      <td>0.785410</td>\n",
       "      <td>0.794974</td>\n",
       "      <td>0.676737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.752858</td>\n",
       "      <td>0.409923</td>\n",
       "      <td>0.568625</td>\n",
       "      <td>0.492306</td>\n",
       "      <td>0.538480</td>\n",
       "      <td>0.029526</td>\n",
       "      <td>0.159570</td>\n",
       "      <td>0.372055</td>\n",
       "      <td>0.989789</td>\n",
       "      <td>0.638766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237853</td>\n",
       "      <td>0.164243</td>\n",
       "      <td>0.353459</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.092722</td>\n",
       "      <td>0.047331</td>\n",
       "      <td>0.358139</td>\n",
       "      <td>0.996793</td>\n",
       "      <td>0.275156</td>\n",
       "      <td>0.031133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.823035</td>\n",
       "      <td>0.803644</td>\n",
       "      <td>0.682427</td>\n",
       "      <td>0.137621</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.911104</td>\n",
       "      <td>0.106425</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.063286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387478</td>\n",
       "      <td>0.139443</td>\n",
       "      <td>0.595708</td>\n",
       "      <td>0.268455</td>\n",
       "      <td>0.569570</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>0.035798</td>\n",
       "      <td>0.707048</td>\n",
       "      <td>0.830126</td>\n",
       "      <td>0.112621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.866232</td>\n",
       "      <td>0.044483</td>\n",
       "      <td>0.928568</td>\n",
       "      <td>0.516422</td>\n",
       "      <td>0.016717</td>\n",
       "      <td>0.579259</td>\n",
       "      <td>0.371929</td>\n",
       "      <td>0.008127</td>\n",
       "      <td>0.860904</td>\n",
       "      <td>0.100397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058718</td>\n",
       "      <td>0.327370</td>\n",
       "      <td>0.700075</td>\n",
       "      <td>0.884156</td>\n",
       "      <td>0.812103</td>\n",
       "      <td>0.428739</td>\n",
       "      <td>0.314069</td>\n",
       "      <td>0.825420</td>\n",
       "      <td>0.276919</td>\n",
       "      <td>0.128554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.874496</td>\n",
       "      <td>0.219341</td>\n",
       "      <td>0.045907</td>\n",
       "      <td>0.476504</td>\n",
       "      <td>0.829157</td>\n",
       "      <td>0.488076</td>\n",
       "      <td>0.403208</td>\n",
       "      <td>0.726149</td>\n",
       "      <td>0.343541</td>\n",
       "      <td>0.242315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388867</td>\n",
       "      <td>0.938230</td>\n",
       "      <td>0.663160</td>\n",
       "      <td>0.315895</td>\n",
       "      <td>0.767613</td>\n",
       "      <td>0.183501</td>\n",
       "      <td>0.799235</td>\n",
       "      <td>0.784662</td>\n",
       "      <td>0.829130</td>\n",
       "      <td>0.748466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_0_feature_0  time_0_feature_1  time_0_feature_2  time_1_feature_0  \\\n",
       "0          0.289801          0.471057          0.781017          0.841905   \n",
       "1          0.752858          0.409923          0.568625          0.492306   \n",
       "2          0.823035          0.803644          0.682427          0.137621   \n",
       "3          0.866232          0.044483          0.928568          0.516422   \n",
       "4          0.874496          0.219341          0.045907          0.476504   \n",
       "\n",
       "   time_1_feature_1  time_1_feature_2  time_2_feature_0  time_2_feature_1  \\\n",
       "0          0.331801          0.229895          0.498487          0.991321   \n",
       "1          0.538480          0.029526          0.159570          0.372055   \n",
       "2          0.213433          0.813559          0.911104          0.106425   \n",
       "3          0.016717          0.579259          0.371929          0.008127   \n",
       "4          0.829157          0.488076          0.403208          0.726149   \n",
       "\n",
       "   time_2_feature_2  time_3_feature_0  ...  time_6_feature_2  \\\n",
       "0          0.053100          0.693752  ...          0.714224   \n",
       "1          0.989789          0.638766  ...          0.237853   \n",
       "2          0.804598          0.063286  ...          0.387478   \n",
       "3          0.860904          0.100397  ...          0.058718   \n",
       "4          0.343541          0.242315  ...          0.388867   \n",
       "\n",
       "   time_7_feature_0  time_7_feature_1  time_7_feature_2  time_8_feature_0  \\\n",
       "0          0.856971          0.828770          0.899247          0.358396   \n",
       "1          0.164243          0.353459          0.142637          0.092722   \n",
       "2          0.139443          0.595708          0.268455          0.569570   \n",
       "3          0.327370          0.700075          0.884156          0.812103   \n",
       "4          0.938230          0.663160          0.315895          0.767613   \n",
       "\n",
       "   time_8_feature_1  time_8_feature_2  time_9_feature_0  time_9_feature_1  \\\n",
       "0          0.281386          0.226141          0.785410          0.794974   \n",
       "1          0.047331          0.358139          0.996793          0.275156   \n",
       "2          0.075283          0.035798          0.707048          0.830126   \n",
       "3          0.428739          0.314069          0.825420          0.276919   \n",
       "4          0.183501          0.799235          0.784662          0.829130   \n",
       "\n",
       "   time_9_feature_2  \n",
       "0          0.676737  \n",
       "1          0.031133  \n",
       "2          0.112621  \n",
       "3          0.128554  \n",
       "4          0.748466  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtype)\n",
    "print(y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_train).sum())\n",
    "print(np.isnan(X_test).sum())\n",
    "print(np.isinf(X_train).sum())\n",
    "print(np.isinf(X_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of numpy.float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize and train TabNet model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m TabNetClassifier()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pytorch_tabnet\\abstract_model.py:262\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Call method on_epoch_end for all callbacks\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_epoch_end(\n\u001b[0;32m    266\u001b[0m     epoch_idx, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mepoch_metrics\n\u001b[0;32m    267\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pytorch_tabnet\\abstract_model.py:561\u001b[0m, in \u001b[0;36mTabModel._predict_epoch\u001b[1;34m(self, name, loader)\u001b[0m\n\u001b[0;32m    558\u001b[0m list_y_score \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Main loop\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_y_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:316\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:173\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    170\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:173\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    170\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:222\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate(\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:222\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not infer dtype of numpy.float32"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train TabNet model\n",
    "model = TabNetClassifier()\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
